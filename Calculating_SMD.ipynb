{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv('/Users/chandramaniyadav/Downloads/NAEP_Competition/NAEP_Math_Challenge_Datasetv1.0/result_VH271613_mathbert1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>true_labels</th>\n",
       "      <th>predicted</th>\n",
       "      <th>score_to_predict</th>\n",
       "      <th>srace10</th>\n",
       "      <th>dsex</th>\n",
       "      <th>accom2</th>\n",
       "      <th>iep</th>\n",
       "      <th>lep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bOo8q8Oj0N</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>qm76aAIl9D</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Si3MMasECV</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CZVb4lFrLE</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lhFUAuLxPL</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>huHHC6Z1gM</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>pdujpF3gGD</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>dwlDM7JMK8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>j1VnE6sVDd</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4177</th>\n",
       "      <td>e2E9CuXxcA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4178 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      student_id  true_labels  predicted  score_to_predict  srace10  dsex   \n",
       "0     bOo8q8Oj0N            1          1                 1      3.0   1.0  \\\n",
       "1     qm76aAIl9D            1          1                 1      1.0   1.0   \n",
       "2     Si3MMasECV            1          1                 1      3.0   2.0   \n",
       "3     CZVb4lFrLE            1          1                 1      3.0   2.0   \n",
       "4     lhFUAuLxPL            1          1                 1      1.0   2.0   \n",
       "...          ...          ...        ...               ...      ...   ...   \n",
       "4173  huHHC6Z1gM            1          1                 1      1.0   1.0   \n",
       "4174  pdujpF3gGD            1          1                 1      1.0   1.0   \n",
       "4175  dwlDM7JMK8            3          3                 3      1.0   2.0   \n",
       "4176  j1VnE6sVDd            1          1                 1      1.0   2.0   \n",
       "4177  e2E9CuXxcA            1          1                 1      1.0   2.0   \n",
       "\n",
       "      accom2  iep  lep  \n",
       "0        1.0  1.0  1.0  \n",
       "1        2.0  1.0  2.0  \n",
       "2        1.0  1.0  2.0  \n",
       "3        2.0  2.0  2.0  \n",
       "4        2.0  2.0  2.0  \n",
       "...      ...  ...  ...  \n",
       "4173     2.0  2.0  2.0  \n",
       "4174     1.0  1.0  2.0  \n",
       "4175     2.0  2.0  2.0  \n",
       "4176     2.0  2.0  2.0  \n",
       "4177     2.0  2.0  2.0  \n",
       "\n",
       "[4178 rows x 9 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_standard_mean_difference(df, predicted_column, true_labels_column, col, value):\n",
    "    if col == 'none' and value == -1 : filtered_df = df\n",
    "    else : filtered_df = df[df[col] == value]\n",
    "\n",
    "    # Filter the DataFrame based on srace10 == 1\n",
    "    \n",
    "\n",
    "\n",
    "    # Calculate the mean and standard deviation for predicted and true_labels columns\n",
    "    mean_predicted = filtered_df[predicted_column].mean()\n",
    "    mean_true_labels = filtered_df[true_labels_column].mean()\n",
    "    std_predicted = filtered_df[predicted_column].std()\n",
    "    std_true_labels = filtered_df[true_labels_column].std()\n",
    "\n",
    "    \n",
    "    # Calculate the sample sizes for predicted and true_labels columns\n",
    "    n_predicted = len(filtered_df[predicted_column])\n",
    "    n_true_labels = len(filtered_df[true_labels_column])\n",
    "\n",
    "\n",
    "    # Calculate the standard mean difference\n",
    "    numerator = mean_predicted - mean_true_labels\n",
    "    denominator = (((n_predicted - 1) * std_predicted**2) + \n",
    "                   ((n_true_labels - 1) * std_true_labels**2)) / (n_predicted + n_true_labels - 2)\n",
    "    smd = numerator / denominator\n",
    "    \n",
    "    return smd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "unique_accessions =  ['VH134067', 'VH139380', 'VH266015', 'VH266510', 'VH269384',\n",
    "                     'VH271613', 'VH302907', 'VH304954', 'VH507804', 'VH525628']\n",
    "# Dictionary to store the dataframes\n",
    "dfs = {}\n",
    "\n",
    "# Folder path\n",
    "folder_path = '/Users/chandramaniyadav/Downloads/NAEP_Competition/NAEP_Math_Challenge_Datasetv1.0/Final Results/'\n",
    "\n",
    "# Loop through the unique accessions\n",
    "for accession in unique_accessions:\n",
    "    # Create the file pattern\n",
    "    file_pattern = folder_path + 'result_' + accession + '*.csv'\n",
    "\n",
    "    # Get the list of files that match the pattern\n",
    "    file_list = glob.glob(file_pattern)\n",
    "\n",
    "    # Check if any files exist\n",
    "    if file_list:\n",
    "        # Read the first CSV file into a dataframe\n",
    "        df = pd.read_csv(file_list[0])\n",
    "\n",
    "        # Add the dataframe to the dictionary\n",
    "        dfs[accession] = df\n",
    "    else:\n",
    "        print(f\"No files found for accession: {accession}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = dfs['VH139380']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srace10</th>\n",
       "      <th>dsex</th>\n",
       "      <th>accom2</th>\n",
       "      <th>iep</th>\n",
       "      <th>lep</th>\n",
       "      <th>student_id</th>\n",
       "      <th>predicted</th>\n",
       "      <th>true_labels</th>\n",
       "      <th>score_to_predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>v65cpQmUxp</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>o9SYEexR1m</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NjlNf7rrp8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7e8OhouIvQ</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0UoYogCzaD</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1811</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>gm8oBiCJKl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1812</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>S5vw4CurMa</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1813</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1p9xlu401K</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6p0uieBgtE</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1815</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>rX6x4b9WIv</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1816 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      srace10  dsex  accom2  iep  lep  student_id  predicted  true_labels   \n",
       "0         3.0   1.0     1.0  1.0  1.0  v65cpQmUxp          1            2  \\\n",
       "1         3.0   1.0     2.0  2.0  2.0  o9SYEexR1m          3            3   \n",
       "2         4.0   1.0     2.0  2.0  2.0  NjlNf7rrp8          3            3   \n",
       "3         2.0   1.0     2.0  2.0  2.0  7e8OhouIvQ          2            2   \n",
       "4         1.0   2.0     2.0  2.0  2.0  0UoYogCzaD          3            3   \n",
       "...       ...   ...     ...  ...  ...         ...        ...          ...   \n",
       "1811      1.0   1.0     2.0  2.0  2.0  gm8oBiCJKl          3            3   \n",
       "1812      1.0   2.0     2.0  2.0  2.0  S5vw4CurMa          2            2   \n",
       "1813      1.0   2.0     2.0  2.0  2.0  1p9xlu401K          1            2   \n",
       "1814      4.0   1.0     2.0  2.0  2.0  6p0uieBgtE          3            3   \n",
       "1815      1.0   2.0     2.0  2.0  2.0  rX6x4b9WIv          3            3   \n",
       "\n",
       "      score_to_predict  \n",
       "0                    2  \n",
       "1                    3  \n",
       "2                    3  \n",
       "3                    2  \n",
       "4                    3  \n",
       "...                ...  \n",
       "1811                 3  \n",
       "1812                 2  \n",
       "1813                 2  \n",
       "1814                 3  \n",
       "1815                 3  \n",
       "\n",
       "[1816 rows x 9 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1['score_to_predict'] = df_1['true_labels']\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_results = {}\n",
    "\n",
    "smd_overall = calculate_standard_mean_difference(df_1, 'predicted', 'score_to_predict', 'none', -1)\n",
    "prompt_results['Overall'] = smd_overall\n",
    "smd_male = calculate_standard_mean_difference(df_1, 'predicted', 'score_to_predict', 'dsex', 1)\n",
    "prompt_results['SMD Male'] = smd_male\n",
    "\n",
    "smd_female = calculate_standard_mean_difference(df_1, 'predicted', 'score_to_predict', 'dsex', 2)\n",
    "prompt_results['SMD Female'] = smd_female\n",
    "\n",
    "smd_accom = calculate_standard_mean_difference(df_1, 'predicted', 'score_to_predict', 'accom2', 1)\n",
    "prompt_results['SMD Accommodated'] = smd_accom\n",
    "\n",
    "smd_non_accom = calculate_standard_mean_difference(df_1, 'predicted', 'score_to_predict', 'accom2', 2)\n",
    "prompt_results['SMD Non-Accommodated'] = smd_non_accom\n",
    "\n",
    "smd_lep = calculate_standard_mean_difference(df_1, 'predicted', 'score_to_predict', 'lep', 1)\n",
    "prompt_results['SMD LEP'] = smd_lep\n",
    "\n",
    "smd_non_lep = calculate_standard_mean_difference(df_1, 'predicted', 'score_to_predict', 'lep', 2)\n",
    "prompt_results['SMD Non LEP'] = smd_non_lep\n",
    "\n",
    "smd_iep = calculate_standard_mean_difference(df_1, 'predicted', 'score_to_predict', 'iep', 1)\n",
    "prompt_results['SMD IEP'] = smd_iep\n",
    "\n",
    "smd_non_iep = calculate_standard_mean_difference(df_1, 'predicted', 'score_to_predict', 'iep', 2)\n",
    "prompt_results['SMD Non IEP'] = smd_non_iep\n",
    "\n",
    "smd_while = calculate_standard_mean_difference(df_1, 'predicted', 'score_to_predict', 'srace10', 1)\n",
    "prompt_results['SMD White'] = smd_while\n",
    "\n",
    "smd_black = calculate_standard_mean_difference(df_1, 'predicted', 'score_to_predict', 'srace10', 2)\n",
    "prompt_results['SMD Black'] = smd_black\n",
    "\n",
    "smd_hispanic = calculate_standard_mean_difference(df_1, 'predicted', 'score_to_predict', 'srace10', 3)\n",
    "prompt_results['SMD Hispanic'] = smd_hispanic\n",
    "\n",
    "smd_asian = calculate_standard_mean_difference(df_1, 'predicted', 'score_to_predict', 'srace10', 4)\n",
    "prompt_results['SMD Asian'] = smd_asian\n",
    "\n",
    "smd_ai = calculate_standard_mean_difference(df_1, 'predicted', 'score_to_predict', 'srace10', 5)\n",
    "prompt_results['SMD American Indian'] = smd_ai\n",
    "\n",
    "smd_pi = calculate_standard_mean_difference(df_1, 'predicted', 'score_to_predict', 'srace10', 6)\n",
    "prompt_results['SMD Pacific Islander'] = smd_pi\n",
    "\n",
    "smd_other = calculate_standard_mean_difference(df_1, 'predicted', 'score_to_predict', 'srace10', 7)\n",
    "prompt_results['SMD Other Race'] = smd_other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Overall': 0.05208506711082012,\n",
       " 'SMD Male': 0.058030046788295556,\n",
       " 'SMD Female': 0.04627616328537145,\n",
       " 'SMD Accommodated': 0.06928239545689227,\n",
       " 'SMD Non-Accommodated': 0.05113869837271549,\n",
       " 'SMD LEP': 0.11300946891725,\n",
       " 'SMD Non LEP': 0.045551914627138215,\n",
       " 'SMD IEP': 0.055678690600871744,\n",
       " 'SMD Non IEP': 0.05454828627204146,\n",
       " 'SMD White': 0.03764705882352938,\n",
       " 'SMD Black': 0.08869438366156056,\n",
       " 'SMD Hispanic': 0.0485858947476087,\n",
       " 'SMD Asian': 0.051106263633531344,\n",
       " 'SMD American Indian': 0.0,\n",
       " 'SMD Pacific Islander': -0.5217391304347825,\n",
       " 'SMD Other Race': 0.16547920018386603}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VH134067\n",
      "VH139380\n",
      "VH266015\n",
      "VH266510\n",
      "VH269384\n",
      "VH271613\n",
      "VH302907\n",
      "VH304954\n",
      "VH507804\n",
      "VH525628\n",
      "  VH134067 VH139380 VH266015 VH266510 VH269384 VH271613 VH302907 VH304954   \n",
      "0      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN  \\\n",
      "1      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
      "2      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
      "3      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
      "4      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
      "5      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
      "6      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
      "7      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
      "8      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
      "9      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
      "\n",
      "  VH507804 VH525628  ... SMD Non LEP   SMD IEP  SMD Non IEP  SMD White   \n",
      "0      NaN      NaN  ...    0.031341  0.000000     0.031822   0.022752  \\\n",
      "1      NaN      NaN  ...    0.045552  0.055679     0.054548   0.037647   \n",
      "2      NaN      NaN  ...   -0.032047 -0.186525    -0.020838  -0.011145   \n",
      "3      NaN      NaN  ...    0.050736 -0.025752     0.052867   0.051631   \n",
      "4      NaN      NaN  ...    0.000659  0.000000     0.002687  -0.013820   \n",
      "5      NaN      NaN  ...    0.073235  0.044882     0.080919   0.060417   \n",
      "6      NaN      NaN  ...    0.031798  0.093567     0.030221   0.026468   \n",
      "7      NaN      NaN  ...    0.076984  0.069372     0.076157   0.066904   \n",
      "8      NaN      NaN  ...    0.028586  0.000000     0.029175   0.031134   \n",
      "9      NaN      NaN  ...    0.018354 -0.028246     0.011799   0.068353   \n",
      "\n",
      "   SMD Black  SMD Hispanic  SMD Asian  SMD American Indian   \n",
      "0   0.050452      0.028183   0.054714            -0.039927  \\\n",
      "1   0.088694      0.048586   0.051106             0.000000   \n",
      "2   0.000000     -0.088876  -0.169014            -0.362606   \n",
      "3   0.062598      0.017426   0.093603             0.084722   \n",
      "4   0.071303      0.040190   0.009347            -0.062712   \n",
      "5   0.216766      0.106507   0.057365            -0.336364   \n",
      "6   0.050732      0.055393   0.040170             0.101560   \n",
      "7   0.224571      0.033755  -0.052285             0.028816   \n",
      "8   0.060048      0.032687  -0.011117            -0.169769   \n",
      "9  -0.089874     -0.107086  -0.023643            -0.390135   \n",
      "\n",
      "   SMD Pacific Islander  SMD Other Race  \n",
      "0              0.096611        0.039681  \n",
      "1             -0.521739        0.165479  \n",
      "2              0.684932        0.154188  \n",
      "3              0.101034        0.067969  \n",
      "4              0.000000       -0.060292  \n",
      "5              2.000000        0.276383  \n",
      "6              0.320225       -0.033193  \n",
      "7              0.000000        0.098472  \n",
      "8             -0.194175        0.000000  \n",
      "9              0.125000       -0.059910  \n",
      "\n",
      "[10 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create an empty dataframe\n",
    "results_df = pd.DataFrame(columns=unique_accessions)\n",
    "\n",
    "# Loop through the unique accessions\n",
    "for prompts in unique_accessions:\n",
    "    df = dfs[str(prompts)]\n",
    "    prompt_results = {}\n",
    "    prompt_results['Prompt'] = prompts\n",
    "\n",
    "    print(prompts)   \n",
    "    smd_overall = calculate_standard_mean_difference(df, 'predicted', 'score_to_predict', 'none', -1)\n",
    "    prompt_results['Overall'] = smd_overall\n",
    "    smd_male = calculate_standard_mean_difference(df, 'predicted', 'score_to_predict', 'dsex', 1)\n",
    "    prompt_results['SMD Male'] = smd_male\n",
    "    \n",
    "    smd_female = calculate_standard_mean_difference(df, 'predicted', 'score_to_predict', 'dsex', 2)\n",
    "    prompt_results['SMD Female'] = smd_female\n",
    "    \n",
    "    smd_accom = calculate_standard_mean_difference(df, 'predicted', 'score_to_predict', 'accom2', 1)\n",
    "    prompt_results['SMD Accommodated'] = smd_accom\n",
    "    \n",
    "    smd_non_accom = calculate_standard_mean_difference(df, 'predicted', 'score_to_predict', 'accom2', 2)\n",
    "    prompt_results['SMD Non-Accommodated'] = smd_non_accom\n",
    "    \n",
    "    smd_lep = calculate_standard_mean_difference(df, 'predicted', 'score_to_predict', 'lep', 1)\n",
    "    prompt_results['SMD LEP'] = smd_lep\n",
    "    \n",
    "    smd_non_lep = calculate_standard_mean_difference(df, 'predicted', 'score_to_predict', 'lep', 2)\n",
    "    prompt_results['SMD Non LEP'] = smd_non_lep\n",
    "    \n",
    "    smd_iep = calculate_standard_mean_difference(df, 'predicted', 'score_to_predict', 'iep', 1)\n",
    "    prompt_results['SMD IEP'] = smd_iep\n",
    "    \n",
    "    smd_non_iep = calculate_standard_mean_difference(df, 'predicted', 'score_to_predict', 'iep', 2)\n",
    "    prompt_results['SMD Non IEP'] = smd_non_iep\n",
    "\n",
    "    smd_while = calculate_standard_mean_difference(df, 'predicted', 'score_to_predict', 'srace10', 1)\n",
    "    prompt_results['SMD White'] = smd_while\n",
    "    \n",
    "    smd_black = calculate_standard_mean_difference(df, 'predicted', 'score_to_predict', 'srace10', 2)\n",
    "    prompt_results['SMD Black'] = smd_black\n",
    "    \n",
    "    smd_hispanic = calculate_standard_mean_difference(df, 'predicted', 'score_to_predict', 'srace10', 3)\n",
    "    prompt_results['SMD Hispanic'] = smd_hispanic\n",
    "    \n",
    "    smd_asian = calculate_standard_mean_difference(df, 'predicted', 'score_to_predict', 'srace10', 4)\n",
    "    prompt_results['SMD Asian'] = smd_asian\n",
    "    \n",
    "    smd_ai = calculate_standard_mean_difference(df, 'predicted', 'score_to_predict', 'srace10', 5)\n",
    "    prompt_results['SMD American Indian'] = smd_ai\n",
    "    \n",
    "    smd_pi = calculate_standard_mean_difference(df, 'predicted', 'score_to_predict', 'srace10', 6)\n",
    "    prompt_results['SMD Pacific Islander'] = smd_pi\n",
    "    \n",
    "    smd_other = calculate_standard_mean_difference(df, 'predicted', 'score_to_predict', 'srace10', 7)\n",
    "    prompt_results['SMD Other Race'] = smd_other\n",
    "    \n",
    "    # Append the prompt results to the dataframe\n",
    "    results_df = pd.concat([results_df, pd.DataFrame(prompt_results, index=[0])], ignore_index=True)\n",
    "\n",
    "# Print the results dataframe\n",
    "print(results_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.2-py2.py3-none-any.whl (249 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.0/250.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_excel('smd_results_5.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "unique_accessions = ['VH134067', 'VH139380', 'VH266015', 'VH266510', 'VH269384',\n",
    "                     'VH271613', 'VH302907', 'VH304954', 'VH507804', 'VH525628']\n",
    "\n",
    "# Source folder containing the files to be copied\n",
    "source_folder = \"/Users/chandramaniyadav/Downloads/NAEP_Competition/NAEP_Math_Challenge_Datasetv1.0/Final Results/\"\n",
    "\n",
    "# Create directories and copy files\n",
    "for accession in unique_accessions:\n",
    "    # Create directory if it doesn't exist\n",
    "    directory = os.path.join(\".\", accession)\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    \n",
    "    # Get the files containing the accession name\n",
    "    matching_files = [file for file in os.listdir(source_folder) if accession in file]\n",
    "    \n",
    "    # Copy the matching files to the directory\n",
    "    for file in matching_files:\n",
    "        source_file = os.path.join(source_folder, file)\n",
    "        destination_file = os.path.join(directory, file)\n",
    "        shutil.copy2(source_file, destination_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "unique_accessions =  ['VH134067', 'VH139380', 'VH266015', 'VH266510', 'VH269384',\n",
    "                     'VH271613', 'VH302907', 'VH304954', 'VH507804', 'VH525628']\n",
    "# Dictionary to store the dataframes\n",
    "dfs_test = {}\n",
    "\n",
    "# Folder path\n",
    "folder_path = '/Users/chandramaniyadav/Downloads/NAEP_Competition/NAEP_Math_Challenge_Datasetv1.0/Final Results/'\n",
    "\n",
    "# Loop through the unique accessions\n",
    "for accession in unique_accessions:\n",
    "    # Create the file pattern\n",
    "    file_pattern = folder_path + 'test_result_' + accession + '*.csv'\n",
    "\n",
    "    # Get the list of files that match the pattern\n",
    "    file_list = glob.glob(file_pattern)\n",
    "\n",
    "    # Check if any files exist\n",
    "    if file_list:\n",
    "        # Read the first CSV file into a dataframe\n",
    "        df = pd.read_csv(file_list[0])\n",
    "\n",
    "        # Add the dataframe to the dictionary\n",
    "        dfs_test[accession] = df\n",
    "    else:\n",
    "        print(f\"No files found for accession: {accession}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "unique_accessions =  ['VH134067', 'VH139380', 'VH266015', 'VH266510', 'VH269384',\n",
    "                     'VH271613', 'VH302907', 'VH304954', 'VH507804', 'VH525628']\n",
    "# Dictionary to store the dataframes\n",
    "dfs_test = {}\n",
    "value_counts_test = {}\n",
    "# Folder path\n",
    "folder_path = '/Users/chandramaniyadav/Downloads/NAEP_Competition/NAEP_Math_Challenge_Datasetv1.0/Final Results/'\n",
    "\n",
    "# Loop through the unique accessions\n",
    "for accession in unique_accessions:\n",
    "    # Create the file pattern\n",
    "    file_pattern = folder_path + 'test_result_' + accession + '*.csv'\n",
    "\n",
    "    # Get the list of files that match the pattern\n",
    "    file_list = glob.glob(file_pattern)\n",
    "\n",
    "    # Check if any files exist\n",
    "    if file_list:\n",
    "        # Read the first CSV file into a dataframe\n",
    "        df = pd.read_csv(file_list[0])\n",
    "        value_counts_test[accession] = df.score_to_predict.value_counts(normalize=True)\n",
    "\n",
    "        # Add the dataframe to the dictionary\n",
    "        dfs_test[accession] = df\n",
    "    else:\n",
    "        print(f\"No files found for accession: {accession}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'VH134067': score_to_predict\n",
       " 1    0.685925\n",
       " 2    0.314075\n",
       " Name: proportion, dtype: float64,\n",
       " 'VH139380': score_to_predict\n",
       " 3    0.440535\n",
       " 2    0.412289\n",
       " 1    0.147175\n",
       " Name: proportion, dtype: float64,\n",
       " 'VH266015': score_to_predict\n",
       " 1    0.807920\n",
       " 2    0.190898\n",
       " 3    0.001182\n",
       " Name: proportion, dtype: float64,\n",
       " 'VH266510': score_to_predict\n",
       " 1    0.764199\n",
       " 3    0.216248\n",
       " 2    0.019553\n",
       " Name: proportion, dtype: float64,\n",
       " 'VH269384': score_to_predict\n",
       " 1    0.804892\n",
       " 3    0.140501\n",
       " 2    0.054608\n",
       " Name: proportion, dtype: float64,\n",
       " 'VH271613': score_to_predict\n",
       " 1    0.955074\n",
       " 3    0.032321\n",
       " 2    0.012605\n",
       " Name: proportion, dtype: float64,\n",
       " 'VH302907': score_to_predict\n",
       " 1    0.806178\n",
       " 2    0.193822\n",
       " Name: proportion, dtype: float64,\n",
       " 'VH304954': score_to_predict\n",
       " 2    0.440029\n",
       " 1    0.345972\n",
       " 3    0.213999\n",
       " Name: proportion, dtype: float64,\n",
       " 'VH507804': score_to_predict\n",
       " 1    0.744574\n",
       " 3    0.181413\n",
       " 2    0.074012\n",
       " Name: proportion, dtype: float64,\n",
       " 'VH525628': score_to_predict\n",
       " 1    0.723451\n",
       " 2    0.160398\n",
       " 3    0.116150\n",
       " Name: proportion, dtype: float64}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_counts_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_value_count_test = pd.DataFrame(value_counts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VH134067</th>\n",
       "      <th>VH139380</th>\n",
       "      <th>VH266015</th>\n",
       "      <th>VH266510</th>\n",
       "      <th>VH269384</th>\n",
       "      <th>VH271613</th>\n",
       "      <th>VH302907</th>\n",
       "      <th>VH304954</th>\n",
       "      <th>VH507804</th>\n",
       "      <th>VH525628</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_to_predict</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.685925</td>\n",
       "      <td>0.147175</td>\n",
       "      <td>0.807920</td>\n",
       "      <td>0.764199</td>\n",
       "      <td>0.804892</td>\n",
       "      <td>0.955074</td>\n",
       "      <td>0.806178</td>\n",
       "      <td>0.345972</td>\n",
       "      <td>0.744574</td>\n",
       "      <td>0.723451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.314075</td>\n",
       "      <td>0.412289</td>\n",
       "      <td>0.190898</td>\n",
       "      <td>0.019553</td>\n",
       "      <td>0.054608</td>\n",
       "      <td>0.012605</td>\n",
       "      <td>0.193822</td>\n",
       "      <td>0.440029</td>\n",
       "      <td>0.074012</td>\n",
       "      <td>0.160398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.440535</td>\n",
       "      <td>0.001182</td>\n",
       "      <td>0.216248</td>\n",
       "      <td>0.140501</td>\n",
       "      <td>0.032321</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.213999</td>\n",
       "      <td>0.181413</td>\n",
       "      <td>0.116150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  VH134067  VH139380  VH266015  VH266510  VH269384  VH271613   \n",
       "score_to_predict                                                               \n",
       "1                 0.685925  0.147175  0.807920  0.764199  0.804892  0.955074  \\\n",
       "2                 0.314075  0.412289  0.190898  0.019553  0.054608  0.012605   \n",
       "3                      NaN  0.440535  0.001182  0.216248  0.140501  0.032321   \n",
       "\n",
       "                  VH302907  VH304954  VH507804  VH525628  \n",
       "score_to_predict                                          \n",
       "1                 0.806178  0.345972  0.744574  0.723451  \n",
       "2                 0.193822  0.440029  0.074012  0.160398  \n",
       "3                      NaN  0.213999  0.181413  0.116150  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_value_count_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "unique_accessions =  ['VH134067', 'VH139380', 'VH266015', 'VH266510', 'VH269384',\n",
    "                     'VH271613', 'VH302907', 'VH304954', 'VH507804', 'VH525628']\n",
    "# Dictionary to store the dataframes\n",
    "dfs_test = {}\n",
    "value_counts = {}\n",
    "# Folder path\n",
    "folder_path = '/Users/chandramaniyadav/Downloads/NAEP_Competition/NAEP_Math_Challenge_Datasetv1.0/Final Results/'\n",
    "\n",
    "# Loop through the unique accessions\n",
    "for accession in unique_accessions:\n",
    "    # Create the file pattern\n",
    "    file_pattern = folder_path + 'test_result_' + accession + '*.csv'\n",
    "\n",
    "    # Get the list of files that match the pattern\n",
    "    file_list = glob.glob(file_pattern)\n",
    "\n",
    "    # Check if any files exist\n",
    "    if file_list:\n",
    "        # Read the first CSV file into a dataframe\n",
    "        df = pd.read_csv(file_list[0])\n",
    "        value_counts[accession] = df.score_to_predict.value_counts(normalize=True)\n",
    "\n",
    "        # Add the dataframe to the dictionary\n",
    "        dfs_test[accession] = df\n",
    "    else:\n",
    "        print(f\"No files found for accession: {accession}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y_/93fvbts118bgkwysz7wjp5p80000gn/T/ipykernel_93890/2382487208.py:21: DtypeWarning: Columns (29,30,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_list[0])\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "unique_accessions =  ['VH134067', 'VH139380', 'VH266015', 'VH266510', 'VH269384',\n",
    "                     'VH271613', 'VH302907', 'VH304954', 'VH507804', 'VH525628']\n",
    "# Dictionary to store the dataframes\n",
    "dfs_main = {}\n",
    "value_counts= {}\n",
    "# Folder path\n",
    "\n",
    "# Loop through the unique accessions\n",
    "for accession in unique_accessions:\n",
    "    # Create the file pattern\n",
    "    file_pattern = 'df_clean' + accession + '.csv'\n",
    "\n",
    "    # Get the list of files that match the pattern\n",
    "    file_list = glob.glob(file_pattern)\n",
    "\n",
    "    # Check if any files exist\n",
    "    if file_list:\n",
    "        # Read the first CSV file into a dataframe\n",
    "        df = pd.read_csv(file_list[0])\n",
    "        value_counts[accession] = df.score_to_predict.value_counts(normalize=True)\n",
    "\n",
    "        # Add the dataframe to the dictionary\n",
    "       # dfs_test[accession] = df\n",
    "    else:\n",
    "        print(f\"No files found for accession: {accession}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'VH134067': score_to_predict\n",
       " 1    0.713475\n",
       " 2    0.286525\n",
       " Name: proportion, dtype: float64,\n",
       " 'VH139380': score_to_predict\n",
       " 2    0.414906\n",
       " 3    0.410211\n",
       " 1    0.174883\n",
       " Name: proportion, dtype: float64,\n",
       " 'VH266015': score_to_predict\n",
       " 1    0.811567\n",
       " 2    0.187022\n",
       " 3    0.001411\n",
       " Name: proportion, dtype: float64,\n",
       " 'VH266510': score_to_predict\n",
       " 1    0.770654\n",
       " 3    0.200100\n",
       " 2    0.029246\n",
       " Name: proportion, dtype: float64,\n",
       " 'VH269384': score_to_predict\n",
       " 1    0.797184\n",
       " 3    0.139555\n",
       " 2    0.063261\n",
       " Name: proportion, dtype: float64,\n",
       " 'VH271613': score_to_predict\n",
       " 1    0.957371\n",
       " 3    0.032169\n",
       " 2    0.010460\n",
       " Name: proportion, dtype: float64,\n",
       " 'VH302907': score_to_predict\n",
       " 1    0.804566\n",
       " 2    0.195434\n",
       " Name: proportion, dtype: float64,\n",
       " 'VH304954': score_to_predict\n",
       " 2    0.455740\n",
       " 1    0.362823\n",
       " 3    0.181437\n",
       " Name: proportion, dtype: float64,\n",
       " 'VH507804': score_to_predict\n",
       " 1    0.744129\n",
       " 3    0.202884\n",
       " 2    0.052987\n",
       " Name: proportion, dtype: float64,\n",
       " 'VH525628': score_to_predict\n",
       " 1    0.711873\n",
       " 2    0.191129\n",
       " 3    0.096998\n",
       " Name: proportion, dtype: float64}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_value_count_all = pd.DataFrame(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VH134067</th>\n",
       "      <th>VH139380</th>\n",
       "      <th>VH266015</th>\n",
       "      <th>VH266510</th>\n",
       "      <th>VH269384</th>\n",
       "      <th>VH271613</th>\n",
       "      <th>VH302907</th>\n",
       "      <th>VH304954</th>\n",
       "      <th>VH507804</th>\n",
       "      <th>VH525628</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_to_predict</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.713475</td>\n",
       "      <td>0.174883</td>\n",
       "      <td>0.811567</td>\n",
       "      <td>0.770654</td>\n",
       "      <td>0.797184</td>\n",
       "      <td>0.957371</td>\n",
       "      <td>0.804566</td>\n",
       "      <td>0.362823</td>\n",
       "      <td>0.744129</td>\n",
       "      <td>0.711873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.286525</td>\n",
       "      <td>0.414906</td>\n",
       "      <td>0.187022</td>\n",
       "      <td>0.029246</td>\n",
       "      <td>0.063261</td>\n",
       "      <td>0.010460</td>\n",
       "      <td>0.195434</td>\n",
       "      <td>0.455740</td>\n",
       "      <td>0.052987</td>\n",
       "      <td>0.191129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.410211</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>0.200100</td>\n",
       "      <td>0.139555</td>\n",
       "      <td>0.032169</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.181437</td>\n",
       "      <td>0.202884</td>\n",
       "      <td>0.096998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  VH134067  VH139380  VH266015  VH266510  VH269384  VH271613   \n",
       "score_to_predict                                                               \n",
       "1                 0.713475  0.174883  0.811567  0.770654  0.797184  0.957371  \\\n",
       "2                 0.286525  0.414906  0.187022  0.029246  0.063261  0.010460   \n",
       "3                      NaN  0.410211  0.001411  0.200100  0.139555  0.032169   \n",
       "\n",
       "                  VH302907  VH304954  VH507804  VH525628  \n",
       "score_to_predict                                          \n",
       "1                 0.804566  0.362823  0.744129  0.711873  \n",
       "2                 0.195434  0.455740  0.052987  0.191129  \n",
       "3                      NaN  0.181437  0.202884  0.096998  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_value_count_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = pd.concat([df_value_count_all, df_value_count_test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "val.to_excel('value_counts.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'VH134067':       student_id accession  score_to_predict   \n",
       " 0     00NK0MwpPa  VH134067                 2  \\\n",
       " 1     00eCiccn2b  VH134067                 1   \n",
       " 2     013BzqWhJ7  VH134067                 1   \n",
       " 3     01x13bb8Ju  VH134067                 2   \n",
       " 4     03Hq2FO3Wu  VH134067                 2   \n",
       " ...          ...       ...               ...   \n",
       " 4478  ztIT6rU6Mb  VH134067                 1   \n",
       " 4479  zwUY5ifIdo  VH134067                 1   \n",
       " 4480  zxlVCqHvxV  VH134067                 2   \n",
       " 4481  zxn3ptbIac  VH134067                 1   \n",
       " 4482  zy4wkBcHpq  VH134067                 1   \n",
       " \n",
       "                                            predict_from  year  srace10  dsex   \n",
       " 0                                                    ×6  2017        3   1.0  \\\n",
       " 1                                         MULTIPLY BY 3  2017        3   1.0   \n",
       " 2           at some point they meet with multiplication  2017        1   1.0   \n",
       " 3     The relationship beetween the input numbers an...  2017        1   2.0   \n",
       " 4     three goes into eighteen six times, four goes ...  2017        3   1.0   \n",
       " ...                                                 ...   ...      ...   ...   \n",
       " 4478                                           diffrent  2019        1   1.0   \n",
       " 4479  the output numbers are bigger than the input n...  2019        1   2.0   \n",
       " 4480                                                 ×6  2019        1   1.0   \n",
       " 4481                                           fzhowqgs  2019        3   2.0   \n",
       " 4482  The input numbers are 1 didget and the output ...  2019        1   2.0   \n",
       " \n",
       "       accom2  iep  lep  ...  eliminated2  eliminated3  eliminated4   \n",
       " 0        1.0  2.0  1.0  ...          NaN          NaN          NaN  \\\n",
       " 1        2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " 2        2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " 3        2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " 4        2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " ...      ...  ...  ...  ...          ...          ...          ...   \n",
       " 4478     2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " 4479     2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " 4480     2.0  2.0  1.0  ...          NaN          NaN          NaN   \n",
       " 4481     1.0  1.0  2.0  ...          NaN          NaN          NaN   \n",
       " 4482     2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " \n",
       "       selected1.1  selected2.1  eliminated1.1  eliminated2.1   \n",
       " 0             NaN          NaN            NaN            NaN  \\\n",
       " 1             NaN          NaN            NaN            NaN   \n",
       " 2             NaN          NaN            NaN            NaN   \n",
       " 3             NaN          NaN            NaN            NaN   \n",
       " 4             NaN          NaN            NaN            NaN   \n",
       " ...           ...          ...            ...            ...   \n",
       " 4478          NaN          NaN            NaN            NaN   \n",
       " 4479          NaN          NaN            NaN            NaN   \n",
       " 4480          NaN          NaN            NaN            NaN   \n",
       " 4481          NaN          NaN            NaN            NaN   \n",
       " 4482          NaN          NaN            NaN            NaN   \n",
       " \n",
       "       partA_response_val partB_response_val  partB_eliminations  \n",
       " 0                    NaN                NaN                 NaN  \n",
       " 1                    NaN                NaN                 NaN  \n",
       " 2                    NaN                NaN                 NaN  \n",
       " 3                    NaN                NaN                 NaN  \n",
       " 4                    NaN                NaN                 NaN  \n",
       " ...                  ...                ...                 ...  \n",
       " 4478                 NaN                NaN                 NaN  \n",
       " 4479                 NaN                NaN                 NaN  \n",
       " 4480                 NaN                NaN                 NaN  \n",
       " 4481                 NaN                NaN                 NaN  \n",
       " 4482                 NaN                NaN                 NaN  \n",
       " \n",
       " [4483 rows x 47 columns],\n",
       " 'VH139380':       student_id accession  score_to_predict   \n",
       " 0     00lHAXZ086  VH139380                 3  \\\n",
       " 1     02GDUgwc34  VH139380                 2   \n",
       " 2     04aD3Quvy2  VH139380                 3   \n",
       " 3     09ruI56gWC  VH139380                 3   \n",
       " 4     0Gf1fefJOB  VH139380                 3   \n",
       " ...          ...       ...               ...   \n",
       " 2013  zuF7MUm0QK  VH139380                 3   \n",
       " 2014  zwBRIbtgRy  VH139380                 2   \n",
       " 2015  zwzqBTRgwS  VH139380                 2   \n",
       " 2016  zyMHsTAcL7  VH139380                 3   \n",
       " 2017  zzS3EF6ayc  VH139380                 2   \n",
       " \n",
       "                                            predict_from  year  srace10  dsex   \n",
       " 0                          you are/will skip count by 3  2019        1   1.0  \\\n",
       " 1     A rule that can be used is to find the number ...  2019        1   2.0   \n",
       " 2                                                    +3  2019        1   1.0   \n",
       " 3                                                    +3  2019        1   2.0   \n",
       " 4     The rule is you have to count by threes to get...  2019        3   2.0   \n",
       " ...                                                 ...   ...      ...   ...   \n",
       " 2013                                                 +3  2019        1   1.0   \n",
       " 2014                                                2,3  2019        3   2.0   \n",
       " 2015                                       11,22,33,44,  2019        7   2.0   \n",
       " 2016                                             ADD 3   2019        1   1.0   \n",
       " 2017  Before you guess number, see what number it is...  2019        4   2.0   \n",
       " \n",
       "       accom2  iep  lep  ...  eliminated2  eliminated3  eliminated4   \n",
       " 0        2.0  2.0  2.0  ...          NaN          NaN          NaN  \\\n",
       " 1        2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " 2        2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " 3        2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " 4        2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " ...      ...  ...  ...  ...          ...          ...          ...   \n",
       " 2013     2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " 2014     2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " 2015     2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " 2016     2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " 2017     2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " \n",
       "       selected1.1  selected2.1  eliminated1.1  eliminated2.1   \n",
       " 0             NaN          NaN            NaN            NaN  \\\n",
       " 1             NaN          NaN            NaN            NaN   \n",
       " 2             NaN          NaN            NaN            NaN   \n",
       " 3             NaN          NaN            NaN            NaN   \n",
       " 4             NaN          NaN            NaN            NaN   \n",
       " ...           ...          ...            ...            ...   \n",
       " 2013          NaN          NaN            NaN            NaN   \n",
       " 2014          NaN          NaN            NaN            NaN   \n",
       " 2015          NaN          NaN            NaN            NaN   \n",
       " 2016          NaN          NaN            NaN            NaN   \n",
       " 2017          NaN          NaN            NaN            NaN   \n",
       " \n",
       "       partA_response_val partB_response_val partB_eliminations  \n",
       " 0                    NaN                NaN                NaN  \n",
       " 1                    NaN                NaN                NaN  \n",
       " 2                    NaN                NaN                NaN  \n",
       " 3                    NaN                NaN                NaN  \n",
       " 4                    NaN                NaN                NaN  \n",
       " ...                  ...                ...                ...  \n",
       " 2013                 NaN                NaN                NaN  \n",
       " 2014                 NaN                NaN                NaN  \n",
       " 2015                 NaN                NaN                NaN  \n",
       " 2016                 NaN                NaN                NaN  \n",
       " 2017                 NaN                NaN                NaN  \n",
       " \n",
       " [2018 rows x 47 columns],\n",
       " 'VH266015':       student_id accession  score_to_predict   \n",
       " 0     03yr8ZiXhl  VH266015                 2  \\\n",
       " 1     050C4NmLo4  VH266015                 1   \n",
       " 2     0A9Z4sthfJ  VH266015                 1   \n",
       " 3     0Duy5W7y7W  VH266015                 1   \n",
       " 4     0FhScpJyU5  VH266015                 1   \n",
       " ...          ...       ...               ...   \n",
       " 1687  zt2lXjziqJ  VH266015                 1   \n",
       " 1688  zuZm8Z2XW4  VH266015                 1   \n",
       " 1689  zvkEeSn5ur  VH266015                 1   \n",
       " 1690  zx0La543X4  VH266015                 1   \n",
       " 1691  zxtI05DQZy  VH266015                 1   \n",
       " \n",
       "                                            predict_from  year  srace10  dsex   \n",
       " 0                                                    43  2019        4   1.0  \\\n",
       " 1                   they have to be equal to each other  2019        3   1.0   \n",
       " 2                                                    76  2019        3   2.0   \n",
       " 3                                              its true  2019        3   2.0   \n",
       " 4                                      that a & b = 7/6  2019        2   2.0   \n",
       " ...                                                 ...   ...      ...   ...   \n",
       " 1687                                    the same values  2019        7   1.0   \n",
       " 1688  The values of a and b should be the same becau...  2019        1   1.0   \n",
       " 1689  One thing that true about values a and b is th...  2019        4   1.0   \n",
       " 1690  The values of a and b must be equal to 7/6 and...  2019        1   2.0   \n",
       " 1691                          they have to be the same   2019        7   2.0   \n",
       " \n",
       "       accom2  iep  lep  ...  eliminated2  eliminated3  eliminated4   \n",
       " 0        2.0  2.0  1.0  ...          NaN          NaN          NaN  \\\n",
       " 1        2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " 2        2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " 3        2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " 4        2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " ...      ...  ...  ...  ...          ...          ...          ...   \n",
       " 1687     2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " 1688     2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " 1689     2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " 1690     2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " 1691     2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " \n",
       "       selected1.1  selected2.1  eliminated1.1  eliminated2.1   \n",
       " 0             NaN          NaN            NaN            NaN  \\\n",
       " 1             NaN          NaN            NaN            NaN   \n",
       " 2             NaN          NaN            NaN            NaN   \n",
       " 3             NaN          NaN            NaN            NaN   \n",
       " 4             NaN          NaN            NaN            NaN   \n",
       " ...           ...          ...            ...            ...   \n",
       " 1687          NaN          NaN            NaN            NaN   \n",
       " 1688          NaN          NaN            NaN            NaN   \n",
       " 1689          NaN          NaN            NaN            NaN   \n",
       " 1690          NaN          NaN            NaN            NaN   \n",
       " 1691          NaN          NaN            NaN            NaN   \n",
       " \n",
       "       partA_response_val partB_response_val  partB_eliminations  \n",
       " 0                    NaN                NaN                 NaN  \n",
       " 1                    NaN                NaN                 NaN  \n",
       " 2                    NaN                NaN                 NaN  \n",
       " 3                    NaN                NaN                 NaN  \n",
       " 4                    NaN                NaN                 NaN  \n",
       " ...                  ...                ...                 ...  \n",
       " 1687                 NaN                NaN                 NaN  \n",
       " 1688                 NaN                NaN                 NaN  \n",
       " 1689                 NaN                NaN                 NaN  \n",
       " 1690                 NaN                NaN                 NaN  \n",
       " 1691                 NaN                NaN                 NaN  \n",
       " \n",
       " [1692 rows x 47 columns],\n",
       " 'VH266510':       student_id accession  score_to_predict   \n",
       " 0     01o2gP1T5c  VH266510                 3  \\\n",
       " 1     030TaOIbqX  VH266510                 1   \n",
       " 2     03dTGeB2DC  VH266510                 1   \n",
       " 3     05KjNbOY1q  VH266510                 3   \n",
       " 4     05ewoQq07p  VH266510                 1   \n",
       " ...          ...       ...               ...   \n",
       " 4291  zs3KrAZLca  VH266510                 1   \n",
       " 4292  zu25UaaoyM  VH266510                 1   \n",
       " 4293  zuZvUCwp3A  VH266510                 1   \n",
       " 4294  zusL336X6L  VH266510                 3   \n",
       " 4295  zxpHsRuAs1  VH266510                 1   \n",
       " \n",
       "                                            predict_from  year  srace10  dsex   \n",
       " 0     becuase if the slopes are equal then they woul...  2017        1   1.0  \\\n",
       " 1     the y alaways intercepts with the x nbeacuse t...  2017        2   2.0   \n",
       " 2     the slope does not have to be equal but the li...  2017        1   2.0   \n",
       " 3     my math teacher said so also because if they h...  2017        1   2.0   \n",
       " 4     the y intercepts the x plane because the meet ...  2017        2   1.0   \n",
       " ...                                                 ...   ...      ...   ...   \n",
       " 4291  because it has to be equal if not they are not...  2019        1   1.0   \n",
       " 4292  how i got this answer is by using or finding t...  2019        1   2.0   \n",
       " 4293  in math if the slope do not add up with the nu...  2019        2   2.0   \n",
       " 4294  if the slopes were the same the lines would be...  2019        7   2.0   \n",
       " 4295  if they were to have the same yintercept and t...  2019        3   2.0   \n",
       " \n",
       "       accom2  iep  lep  ...  eliminated2  eliminated3  eliminated4   \n",
       " 0        2.0  2.0  2.0  ...          NaN          NaN          NaN  \\\n",
       " 1        2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " 2        2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " 3        2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " 4        2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " ...      ...  ...  ...  ...          ...          ...          ...   \n",
       " 4291     1.0  1.0  2.0  ...          NaN          NaN          NaN   \n",
       " 4292     2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " 4293     2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " 4294     2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " 4295     2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " \n",
       "       selected1.1  selected2.1  eliminated1.1  eliminated2.1   \n",
       " 0             NaN          NaN            NaN            NaN  \\\n",
       " 1             NaN          NaN            NaN            NaN   \n",
       " 2             NaN          NaN            NaN            NaN   \n",
       " 3             NaN          NaN            NaN            NaN   \n",
       " 4             NaN          NaN            NaN            NaN   \n",
       " ...           ...          ...            ...            ...   \n",
       " 4291          NaN          NaN            NaN            NaN   \n",
       " 4292          NaN          NaN            NaN            NaN   \n",
       " 4293          NaN          NaN            NaN            NaN   \n",
       " 4294          NaN          NaN            NaN            NaN   \n",
       " 4295          NaN          NaN            NaN            NaN   \n",
       " \n",
       "       partA_response_val partB_response_val  partB_eliminations  \n",
       " 0                    NaN                NaN                 NaN  \n",
       " 1                    NaN                NaN                 NaN  \n",
       " 2                    NaN                NaN                 NaN  \n",
       " 3                    NaN                NaN                 NaN  \n",
       " 4                    NaN                NaN                 NaN  \n",
       " ...                  ...                ...                 ...  \n",
       " 4291                 NaN                NaN                 NaN  \n",
       " 4292                 NaN                NaN                 NaN  \n",
       " 4293                 NaN                NaN                 NaN  \n",
       " 4294                 NaN                NaN                 NaN  \n",
       " 4295                 NaN                NaN                 NaN  \n",
       " \n",
       " [4296 rows x 47 columns],\n",
       " 'VH269384':       student_id accession  score_to_predict   \n",
       " 0     054cy6soYf  VH269384                 1  \\\n",
       " 1     058W34pnDi  VH269384                 1   \n",
       " 2     06WrYsRGuu  VH269384                 3   \n",
       " 3     07Nk2i70eB  VH269384                 1   \n",
       " 4     07zkRRS3Mh  VH269384                 3   \n",
       " ...          ...       ...               ...   \n",
       " 1753  zjhGYyMX61  VH269384                 1   \n",
       " 1754  zlCth3ebQF  VH269384                 3   \n",
       " 1755  zq5XUacrki  VH269384                 1   \n",
       " 1756  zyNwnxEFnh  VH269384                 3   \n",
       " 1757  zzFsH679Fr  VH269384                 3   \n",
       " \n",
       "                                            predict_from  year  srace10  dsex   \n",
       " 0                    I know because 5 is smaller than 9  2019        1   1.0  \\\n",
       " 1     I know because it said that he was playing a g...  2019        1   1.0   \n",
       " 2     I  know because both cards, (the former card a...  2019        1   2.0   \n",
       " 3     He put a card thats bigger then 3 or lower so ...  2019        1   1.0   \n",
       " 4              because they are both greater than three  2019        2   1.0   \n",
       " ...                                                 ...   ...      ...   ...   \n",
       " 1753  I know this because if he takes out a 5 then p...  2019        2   2.0   \n",
       " 1754                          9 is still greater than 3  2019        1   1.0   \n",
       " 1755  i know beacause it says then he puts a 9 card ...  2019        1   2.0   \n",
       " 1756                          they are both more than 3  2019        1   1.0   \n",
       " 1757                          5 and 9 are bigger than 3  2019        3   1.0   \n",
       " \n",
       "       accom2  iep  lep  ...  eliminated2  eliminated3  eliminated4   \n",
       " 0        2.0  2.0  2.0  ...        False        False        False  \\\n",
       " 1        1.0  1.0  2.0  ...        False        False        False   \n",
       " 2        2.0  2.0  2.0  ...        False        False        False   \n",
       " 3        2.0  2.0  2.0  ...        False        False        False   \n",
       " 4        2.0  2.0  2.0  ...        False        False        False   \n",
       " ...      ...  ...  ...  ...          ...          ...          ...   \n",
       " 1753     2.0  2.0  2.0  ...         True        False        False   \n",
       " 1754     2.0  2.0  2.0  ...        False        False        False   \n",
       " 1755     2.0  2.0  2.0  ...        False        False        False   \n",
       " 1756     2.0  2.0  2.0  ...        False        False        False   \n",
       " 1757     1.0  1.0  2.0  ...        False        False        False   \n",
       " \n",
       "       selected1.1  selected2.1  eliminated1.1  eliminated2.1   \n",
       " 0            True        False          False          False  \\\n",
       " 1            True        False          False          False   \n",
       " 2           False         True          False          False   \n",
       " 3           False         True          False          False   \n",
       " 4           False         True          False          False   \n",
       " ...           ...          ...            ...            ...   \n",
       " 1753        False         True           True          False   \n",
       " 1754        False         True          False          False   \n",
       " 1755        False         True          False          False   \n",
       " 1756        False         True          False          False   \n",
       " 1757        False         True          False          False   \n",
       " \n",
       "       partA_response_val partB_response_val  partB_eliminations  \n",
       " 0                    NaN                NaN                 NaN  \n",
       " 1                    NaN                NaN                 NaN  \n",
       " 2                    NaN                NaN                 NaN  \n",
       " 3                    NaN                NaN                 NaN  \n",
       " 4                    NaN                NaN                 NaN  \n",
       " ...                  ...                ...                 ...  \n",
       " 1753                 NaN                NaN                 NaN  \n",
       " 1754                 NaN                NaN                 NaN  \n",
       " 1755                 NaN                NaN                 NaN  \n",
       " 1756                 NaN                NaN                 NaN  \n",
       " 1757                 NaN                NaN                 NaN  \n",
       " \n",
       " [1758 rows x 47 columns],\n",
       " 'VH271613':       student_id accession  score_to_predict   \n",
       " 0     00u9rrqZuh  VH271613                 1  \\\n",
       " 1     02G1Gxbmhf  VH271613                 1   \n",
       " 2     053OYb9O4y  VH271613                 1   \n",
       " 3     05M1oLdPvU  VH271613                 1   \n",
       " 4     06e1PZnECl  VH271613                 1   \n",
       " ...          ...       ...               ...   \n",
       " 3089  zrKGO3SIy8  VH271613                 1   \n",
       " 3090  zutovXyxK3  VH271613                 1   \n",
       " 3091  zw8QXgpLnG  VH271613                 1   \n",
       " 3092  zyyahLMxtS  VH271613                 1   \n",
       " 3093  zza9eNzVr5  VH271613                 1   \n",
       " \n",
       "                                            predict_from  year  srace10  dsex   \n",
       " 0     it seys in the tope Phil's age will be 3 times...  2017        3   1.0  \\\n",
       " 1     zach is younger than Alexs is 6time older than...  2017        2   2.0   \n",
       " 2                                           i dont know  2017        1   2.0   \n",
       " 3                   cause it did not tell you their age  2017        3   1.0   \n",
       " 4     THE STATEMENT IS NOT TRUE BECAUSE PHIL IS 3 TI...  2017        3   2.0   \n",
       " ...                                                 ...   ...      ...   ...   \n",
       " 3089                                                 56  2019        2   1.0   \n",
       " 3090  tim is six years younger then phile so that te...  2019        6   1.0   \n",
       " 3091  Because the amount of how much older you are t...  2019        1   1.0   \n",
       " 3092  Because Zach is already one year younger then ...  2019        7   1.0   \n",
       " 3093             because you don't know how old is alex  2019        2   2.0   \n",
       " \n",
       "       accom2  iep  lep  ...  eliminated2  eliminated3  eliminated4   \n",
       " 0        2.0  2.0  1.0  ...          NaN          NaN          NaN  \\\n",
       " 1        2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " 2        2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " 3        2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " 4        2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " ...      ...  ...  ...  ...          ...          ...          ...   \n",
       " 3089     2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " 3090     1.0  2.0  1.0  ...          NaN          NaN          NaN   \n",
       " 3091     2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " 3092     2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " 3093     2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " \n",
       "       selected1.1  selected2.1  eliminated1.1  eliminated2.1   \n",
       " 0             NaN          NaN            NaN            NaN  \\\n",
       " 1             NaN          NaN            NaN            NaN   \n",
       " 2             NaN          NaN            NaN            NaN   \n",
       " 3             NaN          NaN            NaN            NaN   \n",
       " 4             NaN          NaN            NaN            NaN   \n",
       " ...           ...          ...            ...            ...   \n",
       " 3089          NaN          NaN            NaN            NaN   \n",
       " 3090          NaN          NaN            NaN            NaN   \n",
       " 3091          NaN          NaN            NaN            NaN   \n",
       " 3092          NaN          NaN            NaN            NaN   \n",
       " 3093          NaN          NaN            NaN            NaN   \n",
       " \n",
       "       partA_response_val partB_response_val  partB_eliminations  \n",
       " 0            c(\"2\", \"2\")         c(\"1\", \"\")              list()  \n",
       " 1            c(\"1\", \"1\")         c(\"1\", \"\")              list()  \n",
       " 2            c(\"2\", \"2\")         c(\"\", \"2\")              list()  \n",
       " 3            c(\"2\", \"1\")           c(NA, 2)              list()  \n",
       " 4            c(\"1\", \"1\")         c(\"1\", \"\")              list()  \n",
       " ...                  ...                ...                 ...  \n",
       " 3089                 1 1         TRUE FALSE         FALSE FALSE  \n",
       " 3090                 2 2         TRUE FALSE         FALSE FALSE  \n",
       " 3091                 1 2         FALSE TRUE         FALSE FALSE  \n",
       " 3092                 1 2         FALSE TRUE         FALSE FALSE  \n",
       " 3093                 2 2         TRUE FALSE         FALSE FALSE  \n",
       " \n",
       " [3094 rows x 47 columns],\n",
       " 'VH302907':       student_id accession  score_to_predict   \n",
       " 0     01R1SshJRr  VH302907                 1  \\\n",
       " 1     02VUMWgF0u  VH302907                 1   \n",
       " 2     02gJj5RXOQ  VH302907                 1   \n",
       " 3     05DxgErGjq  VH302907                 1   \n",
       " 4     0APbHollMO  VH302907                 1   \n",
       " ...          ...       ...               ...   \n",
       " 4236  zjKSoxMKLn  VH302907                 1   \n",
       " 4237  zq0O7g1kXG  VH302907                 1   \n",
       " 4238  zwOGtkboto  VH302907                 2   \n",
       " 4239  zy5s8FDzc1  VH302907                 1   \n",
       " 4240  zzk5S4uVsX  VH302907                 1   \n",
       " \n",
       "                                            predict_from  year  srace10  dsex   \n",
       " 0                                                    28  2017        3   1.0  \\\n",
       " 1     The sum of the interior angles is 540 degrees ...  2017        3   2.0   \n",
       " 2                           el 5 es muy pequeno de 540   2017        3   1.0   \n",
       " 3     because they all abtus angles and they have to...  2017        1   2.0   \n",
       " 4                                                    50  2017        1   1.0   \n",
       " ...                                                 ...   ...      ...   ...   \n",
       " 4236                    Because all of them are obtuse.  2019        2   1.0   \n",
       " 4237  because the numbebrs of the angles add up to 540.  2019        1   1.0   \n",
       " 4238                          540÷3=180,180+180+180=540  2019        3   1.0   \n",
       " 4239  It's the sum because you have to use the equat...  2019        4   2.0   \n",
       " 4240            Each side has an angle that you add up.  2019        7   1.0   \n",
       " \n",
       "       accom2  iep  lep  ...  eliminated2  eliminated3  eliminated4   \n",
       " 0        1.0  1.0  2.0  ...          NaN          NaN          NaN  \\\n",
       " 1        2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " 2        1.0  2.0  1.0  ...          NaN          NaN          NaN   \n",
       " 3        2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " 4        1.0  1.0  2.0  ...          NaN          NaN          NaN   \n",
       " ...      ...  ...  ...  ...          ...          ...          ...   \n",
       " 4236     2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " 4237     2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " 4238     1.0  1.0  2.0  ...          NaN          NaN          NaN   \n",
       " 4239     2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " 4240     2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " \n",
       "       selected1.1  selected2.1  eliminated1.1  eliminated2.1   \n",
       " 0             NaN          NaN            NaN            NaN  \\\n",
       " 1             NaN          NaN            NaN            NaN   \n",
       " 2             NaN          NaN            NaN            NaN   \n",
       " 3             NaN          NaN            NaN            NaN   \n",
       " 4             NaN          NaN            NaN            NaN   \n",
       " ...           ...          ...            ...            ...   \n",
       " 4236          NaN          NaN            NaN            NaN   \n",
       " 4237          NaN          NaN            NaN            NaN   \n",
       " 4238          NaN          NaN            NaN            NaN   \n",
       " 4239          NaN          NaN            NaN            NaN   \n",
       " 4240          NaN          NaN            NaN            NaN   \n",
       " \n",
       "       partA_response_val partB_response_val partB_eliminations  \n",
       " 0                    NaN                NaN                NaN  \n",
       " 1                    NaN                NaN                NaN  \n",
       " 2                    NaN                NaN                NaN  \n",
       " 3                    NaN                NaN                NaN  \n",
       " 4                    NaN                NaN                NaN  \n",
       " ...                  ...                ...                ...  \n",
       " 4236                 NaN                NaN                NaN  \n",
       " 4237                 NaN                NaN                NaN  \n",
       " 4238                 NaN                NaN                NaN  \n",
       " 4239                 NaN                NaN                NaN  \n",
       " 4240                 NaN                NaN                NaN  \n",
       " \n",
       " [4241 rows x 47 columns],\n",
       " 'VH304954':       student_id accession  score_to_predict   \n",
       " 0     003MIRjk93  VH304954                 1  \\\n",
       " 1     01eLBIx0h8  VH304954                 2   \n",
       " 2     02SSw23X2v  VH304954                 1   \n",
       " 3     02ZDqkR74T  VH304954                 1   \n",
       " 4     03YPuJr8mR  VH304954                 2   \n",
       " ...          ...       ...               ...   \n",
       " 2738  ztynHEqc3M  VH304954                 3   \n",
       " 2739  zuj9aNvZ2p  VH304954                 2   \n",
       " 2740  zvwB3qEfXW  VH304954                 1   \n",
       " 2741  zyS5JtuhFm  VH304954                 1   \n",
       " 2742  zzf6SIyCkd  VH304954                 1   \n",
       " \n",
       "                                            predict_from  year  srace10  dsex   \n",
       " 0     He needs to subtract the number to find his an...  2017        4   2.0  \\\n",
       " 1                                                 anser  2017        1   1.0   \n",
       " 2     Mark needs to whright the answer to 143-43 as 100  2017        1   2.0   \n",
       " 3                   He need to -to complete the problem  2017        2   1.0   \n",
       " 4                                  Mark has to regroup.  2017        2   2.0   \n",
       " ...                                                 ...   ...      ...   ...   \n",
       " 2738  He needs to subtract 5 from 100 wich will get ...  2017        1   1.0   \n",
       " 2739  Frist Mark need to subtract 43 and 143 and the...  2017        4   1.0   \n",
       " 2740                                          100-48=10  2017        3   2.0   \n",
       " 2741                                subtract 8 from 100  2017        1   1.0   \n",
       " 2742                                                  5  2017        1   1.0   \n",
       " \n",
       "       accom2  iep  lep  ...  eliminated2  eliminated3  eliminated4   \n",
       " 0        NaN  2.0  2.0  ...          NaN          NaN          NaN  \\\n",
       " 1        NaN  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " 2        NaN  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " 3        NaN  1.0  2.0  ...          NaN          NaN          NaN   \n",
       " 4        NaN  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " ...      ...  ...  ...  ...          ...          ...          ...   \n",
       " 2738     NaN  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " 2739     NaN  2.0  1.0  ...          NaN          NaN          NaN   \n",
       " 2740     NaN  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " 2741     NaN  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " 2742     NaN  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " \n",
       "       selected1.1  selected2.1  eliminated1.1  eliminated2.1   \n",
       " 0             NaN          NaN            NaN            NaN  \\\n",
       " 1             NaN          NaN            NaN            NaN   \n",
       " 2             NaN          NaN            NaN            NaN   \n",
       " 3             NaN          NaN            NaN            NaN   \n",
       " 4             NaN          NaN            NaN            NaN   \n",
       " ...           ...          ...            ...            ...   \n",
       " 2738          NaN          NaN            NaN            NaN   \n",
       " 2739          NaN          NaN            NaN            NaN   \n",
       " 2740          NaN          NaN            NaN            NaN   \n",
       " 2741          NaN          NaN            NaN            NaN   \n",
       " 2742          NaN          NaN            NaN            NaN   \n",
       " \n",
       "       partA_response_val partB_response_val partB_eliminations  \n",
       " 0                    NaN                NaN                NaN  \n",
       " 1                    NaN                NaN                NaN  \n",
       " 2                    NaN                NaN                NaN  \n",
       " 3                    NaN                NaN                NaN  \n",
       " 4                    NaN                NaN                NaN  \n",
       " ...                  ...                ...                ...  \n",
       " 2738                 NaN                NaN                NaN  \n",
       " 2739                 NaN                NaN                NaN  \n",
       " 2740                 NaN                NaN                NaN  \n",
       " 2741                 NaN                NaN                NaN  \n",
       " 2742                 NaN                NaN                NaN  \n",
       " \n",
       " [2743 rows x 47 columns],\n",
       " 'VH507804':       student_id accession  score_to_predict   \n",
       " 0     04NoFSBa8L  VH507804                 1  \\\n",
       " 1     06cgyZgZwD  VH507804                 1   \n",
       " 2     0CmVH4sCgo  VH507804                 1   \n",
       " 3     0DotTnLvcL  VH507804                 1   \n",
       " 4     0FebHNmRyB  VH507804                 3   \n",
       " ...          ...       ...               ...   \n",
       " 1792  zvc2Tri4uV  VH507804                 1   \n",
       " 1793  zvmTzDMVLu  VH507804                 1   \n",
       " 1794  zxnuVq3WlV  VH507804                 1   \n",
       " 1795  zxtnowkKPB  VH507804                 3   \n",
       " 1796  zzubuMbn2F  VH507804                 1   \n",
       " \n",
       "                                            predict_from  year  srace10  dsex   \n",
       " 0                                                    54  2019        1   2.0  \\\n",
       " 1             she should have put it in the second box.  2019        1   2.0   \n",
       " 2                                              62×54-17  2019        3   1.0   \n",
       " 3                 the rule is you do it less to gratest  2019        1   2.0   \n",
       " 4     Multiply the largest numbers then add the seco...  2019        7   1.0   \n",
       " ...                                                 ...   ...      ...   ...   \n",
       " 1792                                                 45  2019        1   2.0   \n",
       " 1793                       the larget result is  595939  2019        3   1.0   \n",
       " 1794                                                 62  2019        3   2.0   \n",
       " 1795  Get the largest numbers and mutipliy them then...  2019        1   1.0   \n",
       " 1796                           bigest carde gowes ferst  2019        1   1.0   \n",
       " \n",
       "       accom2  iep  lep  ...  eliminated2  eliminated3  eliminated4   \n",
       " 0        1.0  1.0  2.0  ...          NaN          NaN          NaN  \\\n",
       " 1        2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " 2        2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " 3        2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " 4        2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " ...      ...  ...  ...  ...          ...          ...          ...   \n",
       " 1792     2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " 1793     2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " 1794     1.0  1.0  2.0  ...          NaN          NaN          NaN   \n",
       " 1795     2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " 1796     1.0  1.0  2.0  ...          NaN          NaN          NaN   \n",
       " \n",
       "       selected1.1  selected2.1  eliminated1.1  eliminated2.1   \n",
       " 0             NaN          NaN            NaN            NaN  \\\n",
       " 1             NaN          NaN            NaN            NaN   \n",
       " 2             NaN          NaN            NaN            NaN   \n",
       " 3             NaN          NaN            NaN            NaN   \n",
       " 4             NaN          NaN            NaN            NaN   \n",
       " ...           ...          ...            ...            ...   \n",
       " 1792          NaN          NaN            NaN            NaN   \n",
       " 1793          NaN          NaN            NaN            NaN   \n",
       " 1794          NaN          NaN            NaN            NaN   \n",
       " 1795          NaN          NaN            NaN            NaN   \n",
       " 1796          NaN          NaN            NaN            NaN   \n",
       " \n",
       "       partA_response_val partB_response_val  partB_eliminations  \n",
       " 0                    NaN                NaN                 NaN  \n",
       " 1                    NaN                NaN                 NaN  \n",
       " 2                    NaN                NaN                 NaN  \n",
       " 3                    NaN                NaN                 NaN  \n",
       " 4                    NaN                NaN                 NaN  \n",
       " ...                  ...                ...                 ...  \n",
       " 1792                 NaN                NaN                 NaN  \n",
       " 1793                 NaN                NaN                 NaN  \n",
       " 1794                 NaN                NaN                 NaN  \n",
       " 1795                 NaN                NaN                 NaN  \n",
       " 1796                 NaN                NaN                 NaN  \n",
       " \n",
       " [1797 rows x 47 columns],\n",
       " 'VH525628':       student_id accession  score_to_predict   \n",
       " 0     00otBQ7EYw  VH525628                 1  \\\n",
       " 1     03V0lrI3yf  VH525628                 3   \n",
       " 2     05GiO8Xqky  VH525628                 1   \n",
       " 3     0EqJWJyS1q  VH525628                 3   \n",
       " 4     0IirKFmBh8  VH525628                 3   \n",
       " ...          ...       ...               ...   \n",
       " 1803  zujaRhVvB5  VH525628                 1   \n",
       " 1804  zxEYvBEaKl  VH525628                 3   \n",
       " 1805  zxFKk3hf6Z  VH525628                 1   \n",
       " 1806  zxyqTqJlwS  VH525628                 1   \n",
       " 1807  zya8Ka05Lw  VH525628                 1   \n",
       " \n",
       "                                            predict_from  year  srace10  dsex   \n",
       " 0                                              x2z4y3w1  2019        2   1.0  \\\n",
       " 1     since y and z are less than w and x y and z wo...  2019        1   2.0   \n",
       " 2     if you give each letter a value like 123 and 4...  2019        3   2.0   \n",
       " 3     the two biggest numbers need to be multiplied ...  2019        1   1.0   \n",
       " 4     i know this is the correct answer because you ...  2019        1   1.0   \n",
       " ...                                                 ...   ...      ...   ...   \n",
       " 1803                                               6667  2019        2   1.0   \n",
       " 1804  if z and y are the smallest integers then subt...  2019        1   1.0   \n",
       " 1805  beacuse the it will be confined as one also so...  2019        3   1.0   \n",
       " 1806  i know i am kind of correct because if wxyy is...  2019        3   2.0   \n",
       " 1807             because i am not answering these right  2019        1   1.0   \n",
       " \n",
       "       accom2  iep  lep  ...  eliminated2  eliminated3  eliminated4   \n",
       " 0        2.0  2.0  2.0  ...          NaN          NaN          NaN  \\\n",
       " 1        2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " 2        2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " 3        2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " 4        2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " ...      ...  ...  ...  ...          ...          ...          ...   \n",
       " 1803     1.0  1.0  2.0  ...          NaN          NaN          NaN   \n",
       " 1804     2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " 1805     2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " 1806     2.0  2.0  1.0  ...          NaN          NaN          NaN   \n",
       " 1807     2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       " \n",
       "       selected1.1  selected2.1  eliminated1.1  eliminated2.1   \n",
       " 0             NaN          NaN            NaN            NaN  \\\n",
       " 1             NaN          NaN            NaN            NaN   \n",
       " 2             NaN          NaN            NaN            NaN   \n",
       " 3             NaN          NaN            NaN            NaN   \n",
       " 4             NaN          NaN            NaN            NaN   \n",
       " ...           ...          ...            ...            ...   \n",
       " 1803          NaN          NaN            NaN            NaN   \n",
       " 1804          NaN          NaN            NaN            NaN   \n",
       " 1805          NaN          NaN            NaN            NaN   \n",
       " 1806          NaN          NaN            NaN            NaN   \n",
       " 1807          NaN          NaN            NaN            NaN   \n",
       " \n",
       "       partA_response_val partB_response_val  partB_eliminations  \n",
       " 0                    NaN                NaN                 NaN  \n",
       " 1                    NaN                NaN                 NaN  \n",
       " 2                    NaN                NaN                 NaN  \n",
       " 3                    NaN                NaN                 NaN  \n",
       " 4                    NaN                NaN                 NaN  \n",
       " ...                  ...                ...                 ...  \n",
       " 1803                 NaN                NaN                 NaN  \n",
       " 1804                 NaN                NaN                 NaN  \n",
       " 1805                 NaN                NaN                 NaN  \n",
       " 1806                 NaN                NaN                 NaN  \n",
       " 1807                 NaN                NaN                 NaN  \n",
       " \n",
       " [1808 rows x 47 columns]}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       student_id accession  score_to_predict   \n",
      "0      00NK0MwpPa  VH134067                 2  \\\n",
      "2980   BmIn9EJsNz  VH134067                 1   \n",
      "2981   BmyzJKwDZ6  VH134067                 1   \n",
      "2982   BnJkcuSQ6R  VH134067                 1   \n",
      "2983   Bpk1eoK3cG  VH134067                 1   \n",
      "...           ...       ...               ...   \n",
      "26717  KbAh1Uwoe3  VH525628                 2   \n",
      "26716  KQkZKlkyd0  VH525628                 1   \n",
      "26715  KPNEnYEUxq  VH525628                 1   \n",
      "26741  LWbw7F6Mvf  VH525628                 1   \n",
      "27929  zya8Ka05Lw  VH525628                 1   \n",
      "\n",
      "                                            predict_from  year  srace10  dsex   \n",
      "0                                                     ×6  2017        3   1.0  \\\n",
      "2980   You can multiply two inputs and get an output....  2019        1   2.0   \n",
      "2981   the nimbers are going in order but no 1 2 just...  2019        2   1.0   \n",
      "2982                                         the moltpis  2019        1   2.0   \n",
      "2983   For the first input and output 6 because 6×3=1...  2019        2   2.0   \n",
      "...                                                  ...   ...      ...   ...   \n",
      "26717  if you subtract a higher number from a lower n...  2019        1   1.0   \n",
      "26716                        i know my answer is correct  2019        3   1.0   \n",
      "26715   because you add the biggest and multiply y and w  2019        3   1.0   \n",
      "26741                  because they are in correct order  2019        2   1.0   \n",
      "27929             because i am not answering these right  2019        1   1.0   \n",
      "\n",
      "       accom2  iep  lep  ...  eliminated2  eliminated3  eliminated4   \n",
      "0         1.0  2.0  1.0  ...          NaN          NaN          NaN  \\\n",
      "2980      2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
      "2981      2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
      "2982      1.0  1.0  2.0  ...          NaN          NaN          NaN   \n",
      "2983      2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
      "...       ...  ...  ...  ...          ...          ...          ...   \n",
      "26717     2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
      "26716     2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
      "26715     2.0  2.0  1.0  ...          NaN          NaN          NaN   \n",
      "26741     1.0  1.0  2.0  ...          NaN          NaN          NaN   \n",
      "27929     2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
      "\n",
      "       selected1.1  selected2.1  eliminated1.1  eliminated2.1   \n",
      "0              NaN          NaN            NaN            NaN  \\\n",
      "2980           NaN          NaN            NaN            NaN   \n",
      "2981           NaN          NaN            NaN            NaN   \n",
      "2982           NaN          NaN            NaN            NaN   \n",
      "2983           NaN          NaN            NaN            NaN   \n",
      "...            ...          ...            ...            ...   \n",
      "26717          NaN          NaN            NaN            NaN   \n",
      "26716          NaN          NaN            NaN            NaN   \n",
      "26715          NaN          NaN            NaN            NaN   \n",
      "26741          NaN          NaN            NaN            NaN   \n",
      "27929          NaN          NaN            NaN            NaN   \n",
      "\n",
      "       partA_response_val partB_response_val partB_eliminations  \n",
      "0                     NaN                NaN                NaN  \n",
      "2980                  NaN                NaN                NaN  \n",
      "2981                  NaN                NaN                NaN  \n",
      "2982                  NaN                NaN                NaN  \n",
      "2983                  NaN                NaN                NaN  \n",
      "...                   ...                ...                ...  \n",
      "26717                 NaN                NaN                NaN  \n",
      "26716                 NaN                NaN                NaN  \n",
      "26715                 NaN                NaN                NaN  \n",
      "26741                 NaN                NaN                NaN  \n",
      "27929                 NaN                NaN                NaN  \n",
      "\n",
      "[27930 rows x 47 columns]\n"
     ]
    }
   ],
   "source": [
    "# Concatenate dataframes\n",
    "concatenated_df = pd.concat(dfs_test.values(), ignore_index=True)\n",
    "\n",
    "# Sort dataframe by accession in ascending order\n",
    "concatenated_df.sort_values(by='accession', inplace=True)\n",
    "\n",
    "# Print the concatenated dataframe\n",
    "print(concatenated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_df.to_csv('/Users/chandramaniyadav/Downloads/NAEP_Competition/NAEP_Math_Challenge_Datasetv1.0/test_result_final_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score_to_predict\n",
       "1    19418\n",
       "2     5223\n",
       "3     3289\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated_df['score_to_predict'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y_/93fvbts118bgkwysz7wjp5p80000gn/T/ipykernel_17229/473654489.py:1: DtypeWarning: Columns (20,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_test = pd.read_csv('df_test.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>accession</th>\n",
       "      <th>score_to_predict</th>\n",
       "      <th>predict_from</th>\n",
       "      <th>year</th>\n",
       "      <th>srace10</th>\n",
       "      <th>dsex</th>\n",
       "      <th>accom2</th>\n",
       "      <th>iep</th>\n",
       "      <th>lep</th>\n",
       "      <th>...</th>\n",
       "      <th>eliminated2</th>\n",
       "      <th>eliminated3</th>\n",
       "      <th>eliminated4</th>\n",
       "      <th>selected1.1</th>\n",
       "      <th>selected2.1</th>\n",
       "      <th>eliminated1.1</th>\n",
       "      <th>eliminated2.1</th>\n",
       "      <th>partA_response_val</th>\n",
       "      <th>partB_response_val</th>\n",
       "      <th>partB_eliminations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00NK0MwpPa</td>\n",
       "      <td>VH134067</td>\n",
       "      <td>NaN</td>\n",
       "      <td>×6</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00eCiccn2b</td>\n",
       "      <td>VH134067</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MULTIPLY BY 3</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>013BzqWhJ7</td>\n",
       "      <td>VH134067</td>\n",
       "      <td>NaN</td>\n",
       "      <td>at some point they meet with multiplication</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01x13bb8Ju</td>\n",
       "      <td>VH134067</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The relationship beetween the input numbers an...</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03Hq2FO3Wu</td>\n",
       "      <td>VH134067</td>\n",
       "      <td>NaN</td>\n",
       "      <td>three goes into eighteen six times, four goes ...</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27925</th>\n",
       "      <td>zujaRhVvB5</td>\n",
       "      <td>VH525628</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6667π</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27926</th>\n",
       "      <td>zxEYvBEaKl</td>\n",
       "      <td>VH525628</td>\n",
       "      <td>NaN</td>\n",
       "      <td>If z and y are the smallest integers then subt...</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27927</th>\n",
       "      <td>zxFKk3hf6Z</td>\n",
       "      <td>VH525628</td>\n",
       "      <td>NaN</td>\n",
       "      <td>beacuse the it will be confined as one also so...</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27928</th>\n",
       "      <td>zxyqTqJlwS</td>\n",
       "      <td>VH525628</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I know im kinda correct because if w&gt;x&gt;y&gt;y is ...</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27929</th>\n",
       "      <td>zya8Ka05Lw</td>\n",
       "      <td>VH525628</td>\n",
       "      <td>NaN</td>\n",
       "      <td>because im not answering these right</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27930 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       student_id accession  score_to_predict   \n",
       "0      00NK0MwpPa  VH134067               NaN  \\\n",
       "1      00eCiccn2b  VH134067               NaN   \n",
       "2      013BzqWhJ7  VH134067               NaN   \n",
       "3      01x13bb8Ju  VH134067               NaN   \n",
       "4      03Hq2FO3Wu  VH134067               NaN   \n",
       "...           ...       ...               ...   \n",
       "27925  zujaRhVvB5  VH525628               NaN   \n",
       "27926  zxEYvBEaKl  VH525628               NaN   \n",
       "27927  zxFKk3hf6Z  VH525628               NaN   \n",
       "27928  zxyqTqJlwS  VH525628               NaN   \n",
       "27929  zya8Ka05Lw  VH525628               NaN   \n",
       "\n",
       "                                            predict_from  year  srace10  dsex   \n",
       "0                                                     ×6  2017        3   1.0  \\\n",
       "1                                          MULTIPLY BY 3  2017        3   1.0   \n",
       "2            at some point they meet with multiplication  2017        1   1.0   \n",
       "3      The relationship beetween the input numbers an...  2017        1   2.0   \n",
       "4      three goes into eighteen six times, four goes ...  2017        3   1.0   \n",
       "...                                                  ...   ...      ...   ...   \n",
       "27925                                              6667π  2019        2   1.0   \n",
       "27926  If z and y are the smallest integers then subt...  2019        1   1.0   \n",
       "27927  beacuse the it will be confined as one also so...  2019        3   1.0   \n",
       "27928  I know im kinda correct because if w>x>y>y is ...  2019        3   2.0   \n",
       "27929               because im not answering these right  2019        1   1.0   \n",
       "\n",
       "       accom2  iep  lep  ...  eliminated2  eliminated3  eliminated4   \n",
       "0         1.0  2.0  1.0  ...          NaN          NaN          NaN  \\\n",
       "1         2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       "2         2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       "3         2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       "4         2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       "...       ...  ...  ...  ...          ...          ...          ...   \n",
       "27925     1.0  1.0  2.0  ...          NaN          NaN          NaN   \n",
       "27926     2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       "27927     2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       "27928     2.0  2.0  1.0  ...          NaN          NaN          NaN   \n",
       "27929     2.0  2.0  2.0  ...          NaN          NaN          NaN   \n",
       "\n",
       "       selected1.1  selected2.1  eliminated1.1  eliminated2.1   \n",
       "0              NaN          NaN            NaN            NaN  \\\n",
       "1              NaN          NaN            NaN            NaN   \n",
       "2              NaN          NaN            NaN            NaN   \n",
       "3              NaN          NaN            NaN            NaN   \n",
       "4              NaN          NaN            NaN            NaN   \n",
       "...            ...          ...            ...            ...   \n",
       "27925          NaN          NaN            NaN            NaN   \n",
       "27926          NaN          NaN            NaN            NaN   \n",
       "27927          NaN          NaN            NaN            NaN   \n",
       "27928          NaN          NaN            NaN            NaN   \n",
       "27929          NaN          NaN            NaN            NaN   \n",
       "\n",
       "       partA_response_val partB_response_val partB_eliminations  \n",
       "0                     NaN                NaN                NaN  \n",
       "1                     NaN                NaN                NaN  \n",
       "2                     NaN                NaN                NaN  \n",
       "3                     NaN                NaN                NaN  \n",
       "4                     NaN                NaN                NaN  \n",
       "...                   ...                ...                ...  \n",
       "27925                 NaN                NaN                NaN  \n",
       "27926                 NaN                NaN                NaN  \n",
       "27927                 NaN                NaN                NaN  \n",
       "27928                 NaN                NaN                NaN  \n",
       "27929                 NaN                NaN                NaN  \n",
       "\n",
       "[27930 rows x 47 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('df_test.csv')\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
