{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BO1x0Sej0pvI",
        "outputId": "dcd8f51e-08d1-44e3-c54f-2e05bada9b1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: contractions in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (0.1.73)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from contractions) (0.0.24)\n",
            "Requirement already satisfied: anyascii in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n",
            "Requirement already satisfied: pyahocorasick in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from textsearch>=0.0.21->contractions) (2.0.0)\n",
            "Requirement already satisfied: textsearch in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (0.0.24)\n",
            "Requirement already satisfied: anyascii in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from textsearch) (0.3.2)\n",
            "Requirement already satisfied: pyahocorasick in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from textsearch) (2.0.0)\n",
            "Requirement already satisfied: tqdm in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (4.65.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/chandramaniyadav/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!pip install contractions\n",
        "!pip install textsearch\n",
        "!pip install tqdm\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ghsvOKQXYT6w"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PELwhuhPYHDe",
        "outputId": "4765b88e-bc06-4ed2-a430-d9182881eb88"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/y_/93fvbts118bgkwysz7wjp5p80000gn/T/ipykernel_40337/2496371385.py:1: DtypeWarning: Columns (10,12,15,19,20,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv('item_feature_python_extract_Training_all.csv', encoding = 'utf8')\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('item_feature_python_extract_Training_all.csv', encoding = 'utf8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzOv6Ni14lIW",
        "outputId": "6b5caecb-c233-457f-f988-f98ad4a1caf0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/y_/93fvbts118bgkwysz7wjp5p80000gn/T/ipykernel_40337/3100533466.py:17: DtypeWarning: Columns (29,30,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv( df_name + '.csv')\n"
          ]
        }
      ],
      "source": [
        "# List of unique accessions\n",
        "unique_accessions = ['VH134067', 'VH139380', 'VH266015', 'VH266510', 'VH269384',\n",
        "                     'VH271613', 'VH302907', 'VH304954', 'VH507804', 'VH525628']\n",
        "\n",
        "\n",
        "\n",
        "# Dictionary to store the dataframes\n",
        "dfs = {}\n",
        "\n",
        "# Loop through the unique accessions\n",
        "for accession in unique_accessions:\n",
        "    # Create the dataframe name\n",
        "    \n",
        "    df_name = 'df_' + accession\n",
        "\n",
        "    # Read the CSV file into a dataframe\n",
        "    df = pd.read_csv( df_name + '.csv')\n",
        "\n",
        "    # Add the dataframe to the dictionary\n",
        "    dfs[accession] = df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WRgG8Kyh4qZa"
      },
      "outputs": [],
      "source": [
        "df = dfs['VH304954']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MewGaZzHkIuI",
        "outputId": "4e6d31fc-11c1-4d63-8b2c-df90aa356a17"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0        Mark needs to do next is to add 5 to the answe...\n",
              "1                             he needs to take away 43 -48\n",
              "2         What he needs to do next is subtract 5 from 100.\n",
              "3                          he needs to subtract 5 from 100\n",
              "4                            he needs to solve the problem\n",
              "                               ...                        \n",
              "19550                                 subtract 45 from 100\n",
              "19551    Subtract 95 from 143-43 which the answer for 1...\n",
              "19552                     he needs to subtract 100 from 48\n",
              "19553                                    the answer is 405\n",
              "19554                   know he need's to subtract  143-48\n",
              "Name: predict_from, Length: 19555, dtype: object"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['predict_from']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "T3-VVn34kz8i"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Ro4L68caSeqf"
      },
      "outputs": [],
      "source": [
        "rest_texts, test_texts, rest_labels, test_labels = train_test_split(df['predict_from'], df['assigned_score'], test_size=0.1, random_state=1)\n",
        "train_texts, dev_texts, train_labels, dev_labels = train_test_split(rest_texts, rest_labels, test_size=0.1, random_state=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jTSgt-U-k7dJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size: 15839\n",
            "Dev size: 1760\n",
            "Test size: 1956\n"
          ]
        }
      ],
      "source": [
        "print(\"Train size:\", len(train_texts))\n",
        "print(\"Dev size:\", len(dev_texts))\n",
        "print(\"Test size:\", len(test_texts))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "07cTuBbyn08j"
      },
      "outputs": [],
      "source": [
        "train_labels = train_labels-1\n",
        "dev_labels = dev_labels-1\n",
        "test_labels = test_labels-1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjGqfbdFqyWW"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfcUJjkJlHND",
        "outputId": "c6c51aab-13a6-463f-9924-f075ebd3ed90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers==4.28.0 in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (4.28.0)\n",
            "Requirement already satisfied: filelock in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from transformers==4.28.0) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from transformers==4.28.0) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from transformers==4.28.0) (1.24.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from transformers==4.28.0) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from transformers==4.28.0) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from transformers==4.28.0) (2023.5.5)\n",
            "Requirement already satisfied: requests in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from transformers==4.28.0) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from transformers==4.28.0) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from transformers==4.28.0) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0) (2023.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0) (4.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from requests->transformers==4.28.0) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from requests->transformers==4.28.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from requests->transformers==4.28.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from requests->transformers==4.28.0) (2023.5.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers==4.28.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "0CVw4re-4Ib_"
      },
      "outputs": [],
      "source": [
        "MODEL = \"distilbert-base-uncased\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cM9h4fcF4UtJ",
        "outputId": "d63d5ab4-29f4-4522-f257-f57c3f61ba73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (2.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from datasets) (1.24.3)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from datasets) (12.0.0)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pandas in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from datasets) (2.0.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from datasets) (4.65.0)\n",
            "Requirement already satisfied: xxhash in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: multiprocess in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from datasets) (2023.5.0)\n",
            "Requirement already satisfied: aiohttp in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from datasets) (0.14.1)\n",
            "Requirement already satisfied: packaging in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: responses<0.19 in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from aiohttp->datasets) (3.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.6.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2023.5.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from pandas->datasets) (2023.3)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from pandas->datasets) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1iW5FB2lSVK",
        "outputId": "7e5c8c36-853b-4d74-a718-25bd9cae55e6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from datasets import Dataset,load_dataset, load_from_disk, load_metric\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from transformers import TrainingArguments, Trainer, AdamW\n",
        "\n",
        "# Create model and tokenizer\n",
        "# Make sure the num_labels argument matches the question (it will usually be 2, for correct/incorrect)\n",
        "# Some questions may require more than one model (for more than one written section)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL, num_labels=3)\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXf-aiAP4JE3",
        "outputId": "f74ace07-e2e8-4248-afc4-189b698542c6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Some questions may require more than one model (for more than one written section)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL, num_labels=3)\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "mWdVKQNl4xqi"
      },
      "outputs": [],
      "source": [
        "df['labels'] = df['score_to_predict'] - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOdT0We14spt",
        "outputId": "1a4ddaba-3060-4ab6-ae13-0440f57644c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['student_id', 'accession', 'score_to_predict', 'predict_from', 'year', 'srace10', 'dsex', 'accom2', 'iep', 'lep', 'rater_1', 'pta_rtr1', 'ptb_rtr1', 'ptc_rtr1', 'composite', 'score', 'assigned_score', 'ee_use', 'parsed_xml_v1', 'parsed_xml_v2', 'parsed_xml_v3', 'source1', 'source2', 'source3', 'source4', 'target1', 'target2', 'target3', 'target4', 'eliminations', 'selected', 'eliminated', 'selected1', 'selected2', 'selected3', 'selected4', 'eliminated1', 'eliminated2', 'eliminated3', 'eliminated4', 'selected1.1', 'selected2.1', 'eliminated1.1', 'eliminated2.1', 'partA_response_val', 'partB_response_val', 'partB_eliminations', 'predict_from_withstop', 'predict_from_onestepall', 'n_letter_all', 'n_sentence', 'n_token_verb', 'n_token_adj', 'n_token_noun', 'n_token_adv', 'n_token_content', 'n_token_content_unique', 'n_token_all', 'n_token_alpha', 'n_token_unique', 'word_diversity', 'mean_word_length', 'n_token_non_DaleChall', 'n_token_function', 'brown_popularity', 'n_token_l6', 'pr_token_l6', 'pr_token_cotent', 'equal', 'number', 'numbers', 'one', 'know', 'would', 'lines', 'input', 'older', 'get', 'output', 'phil', 'hundred', 'times', 'years', 'angles', 'add', 'must', 'sides', 'two', 'degrees', 'answer', 'zach', 'true', 'intersect', 'three', 'age', 'point', 'polygon', 'line', 'slope', 'put', 'sum', 'five', 'angle', 'years older', 'alex', 'side', 'going', 'slopes', 'dont', 'six', 'input numbers', 'must equal', 'different', 'output numbers', 'multiply', 'greater', 'intercept', 'interior', ' numb', 'numbe', 'umber', 'number.1', ' numbe', ' number', ' equa', 'equal.1', ' equal', 'inter', 'qual ', 'equal ', ' equal ', ' inte', ' inter', 'mber ', 'bers ', 'mbers', 'umber ', 'number ', ' number ', 'umbers', 'numbers.1', 'mbers ', ' numbers', 'umbers ', 'numbers ', ' line', 'angle.1', 'ould ', ' one ', ' angl', ' angle', ' woul', 'would.1', ' would', ' know', 'know ', ' phil', ' know ', ' side', 'would ', ' would ', 'input.1', ' inpu', ' time', ' input', 'ines ', ' olde', 'lines.1', 'number.2', 'triangles', 'times.1', 'degrees.1', 'numbers.2', 'three.1', 'get.1', 'add.1', 'angles.1', 'equal.2', 'subtract', 'triangle', 'input.2', 'needs', 'sum.1', 'answer.1', 'multiply.1', 'polygon.1', 'output.1', 'would.2', 'rule', 'interior.1', 'six.1', 'equals', 'one.1', 'multiplied', 'interior angles', 'mark', 'three triangles', 'must.1', 'know.1', 'sides.1', 'two.1', 'first', 'make', 'mark needs', 'put.1', 'lines.2', 'since', 'next', 'needs subtract', 'count', 'need', 'every', 'input numbers.1', 'greater.1', 'value', 'always', 'find', 'measures', 'angle.2', ' numb.1', 'umber.1', 'numbe.1', 'number.3', ' numbe.1', ' number.1', ' tria', 'trian', 'gles ', ' trian', 'ngles', 'riang', 'triang', ' triang', 'ngles ', 'angles.2', 'angles ', 'iangl', 'riangl', 'triangl', 'iangle', ' triangl', 'riangle', 'triangle.1', 'mber .1', 'umber .1', 'number .1', ' number .1', ' mult', 'multi', ' multi', 'ultip', 'multip', ' multip', 'ltipl', 'ultipl', 'multipl', ' multipl', ' equa.1', ' time.1', 'equal.3', ' equal.1', 'iangles', 'riangles', 'iangles ', 'times.2', ' times', ' degr', 'degre', 'lines.3', 'would.3', 'number.4', 'equal.4', 'slopes.1', 'subtract.1', 'intersect.1', 'add.2', 'two.2', 'numbers.3', 'slope.1', 'parallel', 'never', 'smallest', 'three.2', 'know.2', 'get.2', 'line.1', 'largest', 'needs.1', 'one.2', 'answer.2', 'lines would', 'slopes lines', 'greater.2', 'slopes equal', 'lines equal', 'two lines', 'point.1', 'biggest', 'equal would', 'never intersect', 'different.1', 'needs subtract.1', 'equal lines', 'multiply.2', 'smallest number', 'would parallel', 'count.1', 'cannot', 'years.1', 'phil.1', 'would never', 'mark.1', 'rule.1', 'value.1', 'always.1', 'least', 'still', 'first.1', ' numb.2', 'umber.2', 'numbe.2', ' numbe.2', 'number.5', ' number.2', ' line.1', ' slop', 'slope.2', ' slope', 'ines .1', 'lines.4', ' lines', 'lines ', ' lines ', 'ould .1', ' woul.1', 'would.4', ' would.1', 'would .1', ' would .1', 'inter.1', 'mber .2', 'umber .2', 'number .2', ' number .2', ' inte.1', ' subt', 'tract', 'subtr', ' subtr', 'ubtra', 'subtra', ' subtra', ' equa.2', 'btrac', 'ubtrac', 'subtrac', ' inter.1', ' subtrac', 'btract', 'ubtract', 'subtract.2', 'equal.5', ' equal.2', 'qual .1', 'equal .1', ' equal .1', 'lopes', 'slopes.2', 'labels'],\n",
              "        num_rows: 15644\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['student_id', 'accession', 'score_to_predict', 'predict_from', 'year', 'srace10', 'dsex', 'accom2', 'iep', 'lep', 'rater_1', 'pta_rtr1', 'ptb_rtr1', 'ptc_rtr1', 'composite', 'score', 'assigned_score', 'ee_use', 'parsed_xml_v1', 'parsed_xml_v2', 'parsed_xml_v3', 'source1', 'source2', 'source3', 'source4', 'target1', 'target2', 'target3', 'target4', 'eliminations', 'selected', 'eliminated', 'selected1', 'selected2', 'selected3', 'selected4', 'eliminated1', 'eliminated2', 'eliminated3', 'eliminated4', 'selected1.1', 'selected2.1', 'eliminated1.1', 'eliminated2.1', 'partA_response_val', 'partB_response_val', 'partB_eliminations', 'predict_from_withstop', 'predict_from_onestepall', 'n_letter_all', 'n_sentence', 'n_token_verb', 'n_token_adj', 'n_token_noun', 'n_token_adv', 'n_token_content', 'n_token_content_unique', 'n_token_all', 'n_token_alpha', 'n_token_unique', 'word_diversity', 'mean_word_length', 'n_token_non_DaleChall', 'n_token_function', 'brown_popularity', 'n_token_l6', 'pr_token_l6', 'pr_token_cotent', 'equal', 'number', 'numbers', 'one', 'know', 'would', 'lines', 'input', 'older', 'get', 'output', 'phil', 'hundred', 'times', 'years', 'angles', 'add', 'must', 'sides', 'two', 'degrees', 'answer', 'zach', 'true', 'intersect', 'three', 'age', 'point', 'polygon', 'line', 'slope', 'put', 'sum', 'five', 'angle', 'years older', 'alex', 'side', 'going', 'slopes', 'dont', 'six', 'input numbers', 'must equal', 'different', 'output numbers', 'multiply', 'greater', 'intercept', 'interior', ' numb', 'numbe', 'umber', 'number.1', ' numbe', ' number', ' equa', 'equal.1', ' equal', 'inter', 'qual ', 'equal ', ' equal ', ' inte', ' inter', 'mber ', 'bers ', 'mbers', 'umber ', 'number ', ' number ', 'umbers', 'numbers.1', 'mbers ', ' numbers', 'umbers ', 'numbers ', ' line', 'angle.1', 'ould ', ' one ', ' angl', ' angle', ' woul', 'would.1', ' would', ' know', 'know ', ' phil', ' know ', ' side', 'would ', ' would ', 'input.1', ' inpu', ' time', ' input', 'ines ', ' olde', 'lines.1', 'number.2', 'triangles', 'times.1', 'degrees.1', 'numbers.2', 'three.1', 'get.1', 'add.1', 'angles.1', 'equal.2', 'subtract', 'triangle', 'input.2', 'needs', 'sum.1', 'answer.1', 'multiply.1', 'polygon.1', 'output.1', 'would.2', 'rule', 'interior.1', 'six.1', 'equals', 'one.1', 'multiplied', 'interior angles', 'mark', 'three triangles', 'must.1', 'know.1', 'sides.1', 'two.1', 'first', 'make', 'mark needs', 'put.1', 'lines.2', 'since', 'next', 'needs subtract', 'count', 'need', 'every', 'input numbers.1', 'greater.1', 'value', 'always', 'find', 'measures', 'angle.2', ' numb.1', 'umber.1', 'numbe.1', 'number.3', ' numbe.1', ' number.1', ' tria', 'trian', 'gles ', ' trian', 'ngles', 'riang', 'triang', ' triang', 'ngles ', 'angles.2', 'angles ', 'iangl', 'riangl', 'triangl', 'iangle', ' triangl', 'riangle', 'triangle.1', 'mber .1', 'umber .1', 'number .1', ' number .1', ' mult', 'multi', ' multi', 'ultip', 'multip', ' multip', 'ltipl', 'ultipl', 'multipl', ' multipl', ' equa.1', ' time.1', 'equal.3', ' equal.1', 'iangles', 'riangles', 'iangles ', 'times.2', ' times', ' degr', 'degre', 'lines.3', 'would.3', 'number.4', 'equal.4', 'slopes.1', 'subtract.1', 'intersect.1', 'add.2', 'two.2', 'numbers.3', 'slope.1', 'parallel', 'never', 'smallest', 'three.2', 'know.2', 'get.2', 'line.1', 'largest', 'needs.1', 'one.2', 'answer.2', 'lines would', 'slopes lines', 'greater.2', 'slopes equal', 'lines equal', 'two lines', 'point.1', 'biggest', 'equal would', 'never intersect', 'different.1', 'needs subtract.1', 'equal lines', 'multiply.2', 'smallest number', 'would parallel', 'count.1', 'cannot', 'years.1', 'phil.1', 'would never', 'mark.1', 'rule.1', 'value.1', 'always.1', 'least', 'still', 'first.1', ' numb.2', 'umber.2', 'numbe.2', ' numbe.2', 'number.5', ' number.2', ' line.1', ' slop', 'slope.2', ' slope', 'ines .1', 'lines.4', ' lines', 'lines ', ' lines ', 'ould .1', ' woul.1', 'would.4', ' would.1', 'would .1', ' would .1', 'inter.1', 'mber .2', 'umber .2', 'number .2', ' number .2', ' inte.1', ' subt', 'tract', 'subtr', ' subtr', 'ubtra', 'subtra', ' subtra', ' equa.2', 'btrac', 'ubtrac', 'subtrac', ' inter.1', ' subtrac', 'btract', 'ubtract', 'subtract.2', 'equal.5', ' equal.2', 'qual .1', 'equal .1', ' equal .1', 'lopes', 'slopes.2', 'labels'],\n",
              "        num_rows: 3911\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Convert to dataset format\n",
        "dataset = Dataset.from_pandas(df, preserve_index=False)\n",
        "dataset = dataset.train_test_split(test_size=0.2, seed=11)\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "2139ade9a52741c08f166ec2a6ffeefb",
            "8f4ff3b84fe746ae84844b9567fea6f4",
            "0505c56e76b946cfb38b04220746db7d",
            "3f01c727ca8b4eaba5ee45ee4a5687b8",
            "57d4a2ee6a024692abc18f0a0ba69dc5",
            "47f1d6b02ea44d3b8dcad40a9f648b7f",
            "3f2609918ee44c23ab439a5744dccc82",
            "ec8528ec1a8442b38dd441513f1a2f72",
            "5f42a99087834ebab2d1776099b483de",
            "ef504371a04c4c54aeefd60c6f5d803d",
            "9cda45e2ba1b4027be226427fb296fe2",
            "eb578059b00d446391527e64921ff366",
            "503a511dd05c44fb8fba2f3f51d0e86b",
            "1a5f91f29eb84c6388dfd16c14b82191",
            "746e2760e40249a3bf2ef950ce7e7ca5",
            "a513fc46de074ab7a79aca4d63bee04e",
            "4e598d91ea604b53be5b03ae66d8649e",
            "4bdabe2bf4e54bbda88fb7058e0aabde",
            "9495b7c1dbf249e9974fa1ff62dee52a",
            "af0af8c5d8934e4ea255effaac53d256",
            "633a7987c787495e83c742a81480be71",
            "f0ec02c823c54901bf1143875ccaa9c6"
          ]
        },
        "id": "JHrViSy-4oVq",
        "outputId": "bdaa9649-39e1-41a4-e093-6a08eacc6284"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                  \r"
          ]
        }
      ],
      "source": [
        "# Tokenize the data\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"parsed_xml_v1\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_dlenrI5MFJ",
        "outputId": "bd2d5bd4-30f1-4c00-e08a-679a7809b67d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Requirement already satisfied: accelerate in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (0.19.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from accelerate) (1.24.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from accelerate) (2.0.1)\n",
            "Requirement already satisfied: filelock in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from torch>=1.6.0->accelerate) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from torch>=1.6.0->accelerate) (4.6.0)\n",
            "Requirement already satisfied: sympy in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from torch>=1.6.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from torch>=1.6.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from torch>=1.6.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install --upgrade accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 964
        },
        "id": "CB_gWEfY5JJp",
        "outputId": "e79af2a0-9824-490b-b771-0b0a6c551a4b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/chandramaniyadav/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "  0%|          | 2/1467 [00:43<8:53:40, 21.86s/it]"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/Users/chandramaniyadav/Downloads/NAEP_Competition/NAEP_Math_Challenge_Datasetv1.0/Copy_of_MathBert.ipynb Cell 21\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chandramaniyadav/Downloads/NAEP_Competition/NAEP_Math_Challenge_Datasetv1.0/Copy_of_MathBert.ipynb#X30sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m training_args \u001b[39m=\u001b[39m TrainingArguments(output_dir\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtest_trainer\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chandramaniyadav/Downloads/NAEP_Competition/NAEP_Math_Challenge_Datasetv1.0/Copy_of_MathBert.ipynb#X30sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                                   logging_strategy\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chandramaniyadav/Downloads/NAEP_Competition/NAEP_Math_Challenge_Datasetv1.0/Copy_of_MathBert.ipynb#X30sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                                   evaluation_strategy\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chandramaniyadav/Downloads/NAEP_Competition/NAEP_Math_Challenge_Datasetv1.0/Copy_of_MathBert.ipynb#X30sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m                                   load_best_model_at_end\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chandramaniyadav/Downloads/NAEP_Competition/NAEP_Math_Challenge_Datasetv1.0/Copy_of_MathBert.ipynb#X30sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                                   )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chandramaniyadav/Downloads/NAEP_Competition/NAEP_Math_Challenge_Datasetv1.0/Copy_of_MathBert.ipynb#X30sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chandramaniyadav/Downloads/NAEP_Competition/NAEP_Math_Challenge_Datasetv1.0/Copy_of_MathBert.ipynb#X30sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chandramaniyadav/Downloads/NAEP_Competition/NAEP_Math_Challenge_Datasetv1.0/Copy_of_MathBert.ipynb#X30sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     args\u001b[39m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chandramaniyadav/Downloads/NAEP_Competition/NAEP_Math_Challenge_Datasetv1.0/Copy_of_MathBert.ipynb#X30sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     compute_metrics\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chandramaniyadav/Downloads/NAEP_Competition/NAEP_Math_Challenge_Datasetv1.0/Copy_of_MathBert.ipynb#X30sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/chandramaniyadav/Downloads/NAEP_Competition/NAEP_Math_Challenge_Datasetv1.0/Copy_of_MathBert.ipynb#X30sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
            "File \u001b[0;32m~/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/transformers/trainer.py:1662\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1657\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[1;32m   1659\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1660\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1661\u001b[0m )\n\u001b[0;32m-> 1662\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1663\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1664\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1665\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1666\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1667\u001b[0m )\n",
            "File \u001b[0;32m~/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/transformers/trainer.py:1929\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1927\u001b[0m         tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1928\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1929\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[1;32m   1931\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1932\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1933\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1934\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1935\u001b[0m ):\n\u001b[1;32m   1936\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1937\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
            "File \u001b[0;32m~/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/transformers/trainer.py:2717\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2715\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdeepspeed\u001b[39m.\u001b[39mbackward(loss)\n\u001b[1;32m   2716\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2717\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m   2719\u001b[0m \u001b[39mreturn\u001b[39;00m loss\u001b[39m.\u001b[39mdetach()\n",
            "File \u001b[0;32m~/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
            "File \u001b[0;32m~/miniconda3/envs/torch-gpu/lib/python3.8/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# AdamW Training\n",
        "training_args = TrainingArguments(output_dir=\"test_trainer\",\n",
        "                                  logging_strategy=\"epoch\",\n",
        "                                  evaluation_strategy=\"epoch\",\n",
        "                                  per_device_train_batch_size=32,\n",
        "                                  per_device_eval_batch_size=32,\n",
        "                                  num_train_epochs=3,\n",
        "                                  save_total_limit = 2,\n",
        "                                  save_strategy = 'no',\n",
        "                                  load_best_model_at_end=False\n",
        "                                  )\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"test\"],\n",
        "    compute_metrics=None,\n",
        ")\n",
        "trainer.train()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0505c56e76b946cfb38b04220746db7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec8528ec1a8442b38dd441513f1a2f72",
            "max": 15644,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5f42a99087834ebab2d1776099b483de",
            "value": 15644
          }
        },
        "1a5f91f29eb84c6388dfd16c14b82191": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9495b7c1dbf249e9974fa1ff62dee52a",
            "max": 3911,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af0af8c5d8934e4ea255effaac53d256",
            "value": 3911
          }
        },
        "2139ade9a52741c08f166ec2a6ffeefb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8f4ff3b84fe746ae84844b9567fea6f4",
              "IPY_MODEL_0505c56e76b946cfb38b04220746db7d",
              "IPY_MODEL_3f01c727ca8b4eaba5ee45ee4a5687b8"
            ],
            "layout": "IPY_MODEL_57d4a2ee6a024692abc18f0a0ba69dc5"
          }
        },
        "3f01c727ca8b4eaba5ee45ee4a5687b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef504371a04c4c54aeefd60c6f5d803d",
            "placeholder": "",
            "style": "IPY_MODEL_9cda45e2ba1b4027be226427fb296fe2",
            "value": " 15644/15644 [00:49&lt;00:00, 306.89 examples/s]"
          }
        },
        "3f2609918ee44c23ab439a5744dccc82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47f1d6b02ea44d3b8dcad40a9f648b7f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bdabe2bf4e54bbda88fb7058e0aabde": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e598d91ea604b53be5b03ae66d8649e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "503a511dd05c44fb8fba2f3f51d0e86b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e598d91ea604b53be5b03ae66d8649e",
            "placeholder": "",
            "style": "IPY_MODEL_4bdabe2bf4e54bbda88fb7058e0aabde",
            "value": "Map: 100%"
          }
        },
        "57d4a2ee6a024692abc18f0a0ba69dc5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "5f42a99087834ebab2d1776099b483de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "633a7987c787495e83c742a81480be71": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "746e2760e40249a3bf2ef950ce7e7ca5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_633a7987c787495e83c742a81480be71",
            "placeholder": "",
            "style": "IPY_MODEL_f0ec02c823c54901bf1143875ccaa9c6",
            "value": " 3911/3911 [00:10&lt;00:00, 342.76 examples/s]"
          }
        },
        "8f4ff3b84fe746ae84844b9567fea6f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47f1d6b02ea44d3b8dcad40a9f648b7f",
            "placeholder": "",
            "style": "IPY_MODEL_3f2609918ee44c23ab439a5744dccc82",
            "value": "Map: 100%"
          }
        },
        "9495b7c1dbf249e9974fa1ff62dee52a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cda45e2ba1b4027be226427fb296fe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a513fc46de074ab7a79aca4d63bee04e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "af0af8c5d8934e4ea255effaac53d256": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb578059b00d446391527e64921ff366": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_503a511dd05c44fb8fba2f3f51d0e86b",
              "IPY_MODEL_1a5f91f29eb84c6388dfd16c14b82191",
              "IPY_MODEL_746e2760e40249a3bf2ef950ce7e7ca5"
            ],
            "layout": "IPY_MODEL_a513fc46de074ab7a79aca4d63bee04e"
          }
        },
        "ec8528ec1a8442b38dd441513f1a2f72": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef504371a04c4c54aeefd60c6f5d803d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0ec02c823c54901bf1143875ccaa9c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
