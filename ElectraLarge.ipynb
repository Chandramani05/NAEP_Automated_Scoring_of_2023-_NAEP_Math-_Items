{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOWWrQsB1eTueDUe4nVCrUL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install transformers==4.28.0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qp2n_HQJLNtH","executionInfo":{"status":"ok","timestamp":1686249525841,"user_tz":240,"elapsed":25993,"user":{"displayName":"Chandramani","userId":"15720194962338037264"}},"outputId":"91bc324a-617e-4918-bdcf-5b0d46a0550c"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers==4.28.0\n","  Downloading transformers-4.28.0-py3-none-any.whl (7.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (3.12.0)\n","Collecting huggingface-hub<1.0,>=0.11.0 (from transformers==4.28.0)\n","  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.28.0)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.0) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.0) (3.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.15.1 tokenizers-0.13.3 transformers-4.28.0\n"]}]},{"cell_type":"code","source":["!pip install pytorch-lightning"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HI6tvfuN_NlE","executionInfo":{"status":"ok","timestamp":1686249544833,"user_tz":240,"elapsed":18999,"user":{"displayName":"Chandramani","userId":"15720194962338037264"}},"outputId":"0d2b4361-48e9-4ed1-fdf7-c9defa7318f3"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pytorch-lightning\n","  Downloading pytorch_lightning-2.0.3-py3-none-any.whl (720 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m720.6/720.6 kB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.22.4)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2.0.1+cu118)\n","Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.65.0)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (6.0)\n","Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2023.4.0)\n","Collecting torchmetrics>=0.7.0 (from pytorch-lightning)\n","  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (23.1)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.5.0)\n","Collecting lightning-utilities>=0.7.0 (from pytorch-lightning)\n","  Downloading lightning_utilities-0.8.0-py3-none-any.whl (20 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2.27.1)\n","Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]>2021.06.0->pytorch-lightning)\n","  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.12.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch-lightning) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch-lightning) (16.0.5)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (2.0.12)\n","Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning)\n","  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning)\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting yarl<2.0,>=1.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning)\n","  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning)\n","  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning)\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->pytorch-lightning) (2.1.2)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.4)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->pytorch-lightning) (1.3.0)\n","Installing collected packages: multidict, lightning-utilities, frozenlist, async-timeout, yarl, aiosignal, aiohttp, torchmetrics, pytorch-lightning\n","Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 lightning-utilities-0.8.0 multidict-6.0.4 pytorch-lightning-2.0.3 torchmetrics-0.11.4 yarl-1.9.2\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1jOzXg9xLI3c","executionInfo":{"status":"ok","timestamp":1686249576680,"user_tz":240,"elapsed":31851,"user":{"displayName":"Chandramani","userId":"15720194962338037264"}},"outputId":"9fc694e4-56ef-4a57-b874-494ccb12daf6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install transformers\n","!pip install datasets\n","!pip install -U git+https://github.com/huggingface/accelerate.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CeDBl8cNLSrw","executionInfo":{"status":"ok","timestamp":1686249624296,"user_tz":240,"elapsed":47634,"user":{"displayName":"Chandramani","userId":"15720194962338037264"}},"outputId":"e1f4e418-2be4-40a9-d293-8752df2dd7c2"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.28.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Collecting dill<0.3.7,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.4)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.15.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n","Collecting responses<0.19 (from datasets)\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Installing collected packages: xxhash, dill, responses, multiprocess, datasets\n","Successfully installed datasets-2.12.0 dill-0.3.6 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/huggingface/accelerate.git\n","  Cloning https://github.com/huggingface/accelerate.git to /tmp/pip-req-build-mga1losv\n","  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate.git /tmp/pip-req-build-mga1losv\n","  Resolved https://github.com/huggingface/accelerate.git to commit 87c81315a1b71da5d6a9129c9d2dc9a31c794bb6\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0.dev0) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0.dev0) (23.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0.dev0) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0.dev0) (6.0)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0.dev0) (2.0.1+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.21.0.dev0) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.21.0.dev0) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.21.0.dev0) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.21.0.dev0) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.21.0.dev0) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate==0.21.0.dev0) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate==0.21.0.dev0) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate==0.21.0.dev0) (16.0.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->accelerate==0.21.0.dev0) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate==0.21.0.dev0) (1.3.0)\n","Building wheels for collected packages: accelerate\n","  Building wheel for accelerate (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for accelerate: filename=accelerate-0.21.0.dev0-py3-none-any.whl size=227654 sha256=084662a486bcaf760703265cc842f2ec04421e563f4e3db2ed575a2fb1ad531b\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-2dgopoze/wheels/9c/a3/1e/47368f9b6575655fe9ee1b6350cfa7d4b0befe66a35f8a8365\n","Successfully built accelerate\n","Installing collected packages: accelerate\n","Successfully installed accelerate-0.21.0.dev0\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import os\n","import pandas as pd\n","import random\n","import seaborn as sns\n","\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import roc_curve\n","import tensorflow as tf\n","from tensorflow.keras import backend as K\n","from tensorflow.keras import initializers\n","from transformers import DistilBertTokenizerFast\n","from transformers import TFDistilBertModel, DistilBertConfig\n","from transformers import AutoTokenizer"],"metadata":{"id":"puF4JaIwLXAJ","executionInfo":{"status":"ok","timestamp":1686249634843,"user_tz":240,"elapsed":10562,"user":{"displayName":"Chandramani","userId":"15720194962338037264"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# List of unique accessions\n","unique_accessions = ['VH134067', 'VH139380', 'VH266015', 'VH266510', 'VH269384',\n","                     'VH271613', 'VH302907', 'VH304954', 'VH507804', 'VH525628']\n","\n","\n","\n","# Dictionary to store the dataframes\n","dfs = {}\n","\n","# Loop through the unique accessions\n","for accession in unique_accessions:\n","    # Create the dataframe name\n","    path = '/content/drive/MyDrive/NAEP_Comp/'\n","    df_name = 'df_' + accession\n","\n","    # Read the CSV file into a dataframe\n","    df = pd.read_csv(path + df_name + '.csv')\n","\n","    # Add the dataframe to the dictionary\n","    dfs[accession] = df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OAadOUhvL_3x","executionInfo":{"status":"ok","timestamp":1686249654545,"user_tz":240,"elapsed":19738,"user":{"displayName":"Chandramani","userId":"15720194962338037264"}},"outputId":"25da65d4-3e30-4499-9c90-83bfdeb72564"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-6-4e4dfdd30b27>:17: DtypeWarning: Columns (29,30,31) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv(path + df_name + '.csv')\n"]}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split"],"metadata":{"id":"p6qziW8hSMOJ","executionInfo":{"status":"ok","timestamp":1686249654546,"user_tz":240,"elapsed":29,"user":{"displayName":"Chandramani","userId":"15720194962338037264"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["from transformers import RobertaTokenizerFast\n","from transformers import TFRobertaModel"],"metadata":{"id":"dwcws4mPSMcQ","executionInfo":{"status":"ok","timestamp":1686249654547,"user_tz":240,"elapsed":21,"user":{"displayName":"Chandramani","userId":"15720194962338037264"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import transformers\n","import torch\n","import csv\n","\n","from datasets import Dataset,load_dataset, load_from_disk, load_metric\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","from transformers import TrainingArguments, Trainer, AdamW\n","from sklearn.metrics import cohen_kappa_score\n","from torch.utils.data import DataLoader"],"metadata":{"id":"vD1mEhJySV1C","executionInfo":{"status":"ok","timestamp":1686249655705,"user_tz":240,"elapsed":1179,"user":{"displayName":"Chandramani","userId":"15720194962338037264"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["df = dfs['VH525628']"],"metadata":{"id":"lR0lOmb1DWnI","executionInfo":{"status":"ok","timestamp":1686249655710,"user_tz":240,"elapsed":43,"user":{"displayName":"Chandramani","userId":"15720194962338037264"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["import torch\n","if torch.cuda.is_available():  \n","    device = torch.device(\"cuda\")\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","    \n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hjr_AypXEhqz","executionInfo":{"status":"ok","timestamp":1686249655711,"user_tz":240,"elapsed":42,"user":{"displayName":"Chandramani","userId":"15720194962338037264"}},"outputId":"02bc3f7d-e295-43bd-c82e-3e9804da5c53"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["We will use the GPU: Tesla T4\n"]}]},{"cell_type":"code","source":["import os, sys, itertools, re\n"],"metadata":{"id":"Oe4QFS4HEioe","executionInfo":{"status":"ok","timestamp":1686249655711,"user_tz":240,"elapsed":29,"user":{"displayName":"Chandramani","userId":"15720194962338037264"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","df = df.dropna(subset = ['predict_from'])"],"metadata":{"id":"2h9FerojEmz5","executionInfo":{"status":"ok","timestamp":1686249655712,"user_tz":240,"elapsed":29,"user":{"displayName":"Chandramani","userId":"15720194962338037264"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["def preprocess(text):\n","    text=text.lower()\n","    # remove hyperlinks\n","    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text)\n","    text = re.sub(r'http?:\\/\\/.*[\\r\\n]*', '', text)\n","    #Replace &amp, &lt, &gt with &,<,> respectively\n","    text=text.replace(r'&amp;?',r'and')\n","    text=text.replace(r'&lt;',r'<')\n","    text=text.replace(r'&gt;',r'>')\n","    #remove hashtag sign\n","    #text=re.sub(r\"#\",\"\",text)   \n","    #remove mentions\n","    text = re.sub(r\"(?:\\@)\\w+\", '', text)\n","    #text=re.sub(r\"@\",\"\",text)\n","    #remove non ascii chars\n","    text=text.encode(\"ascii\",errors=\"ignore\").decode()\n","    #remove some puncts (except . ! ?)\n","    text=re.sub(r'[:\"#$%&\\*+,-/:;<=>@\\\\^_`{|}~]+','',text)\n","    text=re.sub(r'[!]+','!',text)\n","    text=re.sub(r'[?]+','?',text)\n","    text=re.sub(r'[.]+','.',text)\n","    text=re.sub(r\"'\",\"\",text)\n","    text=re.sub(r\"\\(\",\"\",text)\n","    text=re.sub(r\"\\)\",\"\",text)\n","    \n","    text=\" \".join(text.split())\n","    return text\n","\n","df['predict_from'] = df['predict_from'].apply(preprocess)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wkt3TIW9ERdJ","executionInfo":{"status":"ok","timestamp":1686249656298,"user_tz":240,"elapsed":615,"user":{"displayName":"Chandramani","userId":"15720194962338037264"}},"outputId":"8aa79a89-365b-4d8e-9130-27179373e03d"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-14-9ec5fd376bef>:29: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df['predict_from'] = df['predict_from'].apply(preprocess)\n"]}]},{"cell_type":"code","source":["df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"0jARQ-Lj6n2Y","executionInfo":{"status":"ok","timestamp":1686249656299,"user_tz":240,"elapsed":15,"user":{"displayName":"Chandramani","userId":"15720194962338037264"}},"outputId":"742bc558-c4c8-4d73-d252-7c49e338fdac"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       student_id accession  score_to_predict  \\\n","0      00ONGl5PbU  VH525628                 1   \n","1      00Pyb7DQQJ  VH525628                 1   \n","2      00mk2jVZeW  VH525628                 3   \n","3      00oZfN72Ey  VH525628                 1   \n","4      016tN2x0ht  VH525628                 2   \n","...           ...       ...               ...   \n","15686  zz3FYf9ZrL  VH525628                 2   \n","15687  zzVfhFCqxZ  VH525628                 1   \n","15688  zzZzqUS7Af  VH525628                 1   \n","15689  zzaK4OQKHC  VH525628                 1   \n","15690  zzqkLorbrU  VH525628                 1   \n","\n","                                            predict_from  year  srace10  dsex  \\\n","0      i believe im right because if you get the bige...  2019      1.0   1.0   \n","1      i know this might be right because of the x an...  2019      3.0   2.0   \n","2      since z is the smallest and w the biggest you ...  2019      4.0   1.0   \n","3      i know because x always comes first then z is ...  2019      1.0   2.0   \n","4      i know this answer is correct because if you a...  2019      1.0   1.0   \n","...                                                  ...   ...      ...   ...   \n","15686  because when you put them in this order you ar...  2019      1.0   2.0   \n","15687  if you were to add w and x and subsitute it fo...  2019      1.0   1.0   \n","15688                                     there in order  2019      3.0   1.0   \n","15689                                        i dont know  2019      1.0   2.0   \n","15690  flip flopping each letter to create the least ...  2019      1.0   1.0   \n","\n","       accom2  iep  lep  ... equal.5   equal.2  qual .1  equal .1   equal .1  \\\n","0         2.0  2.0  2.0  ...       0         0        0         0          0   \n","1         2.0  2.0  2.0  ...       0         0        0         0          0   \n","2         2.0  2.0  2.0  ...       0         0        0         0          0   \n","3         1.0  1.0  2.0  ...       0         0        0         0          0   \n","4         2.0  2.0  2.0  ...       0         0        0         0          0   \n","...       ...  ...  ...  ...     ...       ...      ...       ...        ...   \n","15686     2.0  2.0  2.0  ...       0         0        0         0          0   \n","15687     1.0  1.0  2.0  ...       0         0        0         0          0   \n","15688     1.0  1.0  2.0  ...       0         0        0         0          0   \n","15689     2.0  2.0  2.0  ...       0         0        0         0          0   \n","15690     2.0  2.0  2.0  ...       0         0        0         0          0   \n","\n","      lopes  slopes.2                                               text  \\\n","0         0         0  believe im right get bigest numbers u subtract...   \n","1         0         0  know might right x axis ones w z showw thier s...   \n","2         0         0  since z smallest w biggest take two smallest z...   \n","3         0         0  know x always comes first z equivelent x w goi...   \n","4         0         0  know answer correct add lowest numbers togeter...   \n","...     ...       ...                                                ...   \n","15686     0         0  put order subtracting biggest number possible ...   \n","15687     0         0  add w x subsitute result would multiply z subs...   \n","15688     0         0                                              order   \n","15689     0         0                                          dont know   \n","15690     0         0            flip flopping letter create least value   \n","\n","                                               text_cont  \\\n","0      believe i am right get bigest numbers you subt...   \n","1      know might right x axis ones w z showw thier s...   \n","2      since z smallest w biggest take two smallest z...   \n","3      know x always comes first z equivelent x w goi...   \n","4      know answer correct add lowest numbers togeter...   \n","...                                                  ...   \n","15686  put order subtracting biggest number possible ...   \n","15687  add w x subsitute result would multiply z subs...   \n","15688                                              order   \n","15689                                        do not know   \n","15690            flip flopping letter create least value   \n","\n","                                               text_blob  \n","0      believe im right get bigest numbers u subtract...  \n","1      know might right x axis ones w z showw thier s...  \n","2      since z smallest w biggest take two smallest z...  \n","3      know x always comes first z equivelent x w goi...  \n","4      know answer correct add lowest numbers togeter...  \n","...                                                  ...  \n","15686  put order subtracting biggest number possible ...  \n","15687  add w x subsitute result would multiply z subs...  \n","15688                                              order  \n","15689                                          dont know  \n","15690            flip flopping letter create least value  \n","\n","[15683 rows x 371 columns]"],"text/html":["\n","  <div id=\"df-6c6d01e2-7fcf-4b4b-91e9-b349de3ee418\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>student_id</th>\n","      <th>accession</th>\n","      <th>score_to_predict</th>\n","      <th>predict_from</th>\n","      <th>year</th>\n","      <th>srace10</th>\n","      <th>dsex</th>\n","      <th>accom2</th>\n","      <th>iep</th>\n","      <th>lep</th>\n","      <th>...</th>\n","      <th>equal.5</th>\n","      <th>equal.2</th>\n","      <th>qual .1</th>\n","      <th>equal .1</th>\n","      <th>equal .1</th>\n","      <th>lopes</th>\n","      <th>slopes.2</th>\n","      <th>text</th>\n","      <th>text_cont</th>\n","      <th>text_blob</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>00ONGl5PbU</td>\n","      <td>VH525628</td>\n","      <td>1</td>\n","      <td>i believe im right because if you get the bige...</td>\n","      <td>2019</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>believe im right get bigest numbers u subtract...</td>\n","      <td>believe i am right get bigest numbers you subt...</td>\n","      <td>believe im right get bigest numbers u subtract...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>00Pyb7DQQJ</td>\n","      <td>VH525628</td>\n","      <td>1</td>\n","      <td>i know this might be right because of the x an...</td>\n","      <td>2019</td>\n","      <td>3.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>know might right x axis ones w z showw thier s...</td>\n","      <td>know might right x axis ones w z showw thier s...</td>\n","      <td>know might right x axis ones w z showw thier s...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>00mk2jVZeW</td>\n","      <td>VH525628</td>\n","      <td>3</td>\n","      <td>since z is the smallest and w the biggest you ...</td>\n","      <td>2019</td>\n","      <td>4.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>since z smallest w biggest take two smallest z...</td>\n","      <td>since z smallest w biggest take two smallest z...</td>\n","      <td>since z smallest w biggest take two smallest z...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>00oZfN72Ey</td>\n","      <td>VH525628</td>\n","      <td>1</td>\n","      <td>i know because x always comes first then z is ...</td>\n","      <td>2019</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>know x always comes first z equivelent x w goi...</td>\n","      <td>know x always comes first z equivelent x w goi...</td>\n","      <td>know x always comes first z equivelent x w goi...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>016tN2x0ht</td>\n","      <td>VH525628</td>\n","      <td>2</td>\n","      <td>i know this answer is correct because if you a...</td>\n","      <td>2019</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>know answer correct add lowest numbers togeter...</td>\n","      <td>know answer correct add lowest numbers togeter...</td>\n","      <td>know answer correct add lowest numbers togeter...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>15686</th>\n","      <td>zz3FYf9ZrL</td>\n","      <td>VH525628</td>\n","      <td>2</td>\n","      <td>because when you put them in this order you ar...</td>\n","      <td>2019</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>put order subtracting biggest number possible ...</td>\n","      <td>put order subtracting biggest number possible ...</td>\n","      <td>put order subtracting biggest number possible ...</td>\n","    </tr>\n","    <tr>\n","      <th>15687</th>\n","      <td>zzVfhFCqxZ</td>\n","      <td>VH525628</td>\n","      <td>1</td>\n","      <td>if you were to add w and x and subsitute it fo...</td>\n","      <td>2019</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>add w x subsitute result would multiply z subs...</td>\n","      <td>add w x subsitute result would multiply z subs...</td>\n","      <td>add w x subsitute result would multiply z subs...</td>\n","    </tr>\n","    <tr>\n","      <th>15688</th>\n","      <td>zzZzqUS7Af</td>\n","      <td>VH525628</td>\n","      <td>1</td>\n","      <td>there in order</td>\n","      <td>2019</td>\n","      <td>3.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>order</td>\n","      <td>order</td>\n","      <td>order</td>\n","    </tr>\n","    <tr>\n","      <th>15689</th>\n","      <td>zzaK4OQKHC</td>\n","      <td>VH525628</td>\n","      <td>1</td>\n","      <td>i dont know</td>\n","      <td>2019</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>dont know</td>\n","      <td>do not know</td>\n","      <td>dont know</td>\n","    </tr>\n","    <tr>\n","      <th>15690</th>\n","      <td>zzqkLorbrU</td>\n","      <td>VH525628</td>\n","      <td>1</td>\n","      <td>flip flopping each letter to create the least ...</td>\n","      <td>2019</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>2.0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>flip flopping letter create least value</td>\n","      <td>flip flopping letter create least value</td>\n","      <td>flip flopping letter create least value</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>15683 rows × 371 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c6d01e2-7fcf-4b4b-91e9-b349de3ee418')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6c6d01e2-7fcf-4b4b-91e9-b349de3ee418 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6c6d01e2-7fcf-4b4b-91e9-b349de3ee418');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["df[\"score_to_predict\"].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DXuCjH3_FMbs","executionInfo":{"status":"ok","timestamp":1686249656300,"user_tz":240,"elapsed":13,"user":{"displayName":"Chandramani","userId":"15720194962338037264"}},"outputId":"f3df7992-1e1a-48bf-c483-bc2e806852f2"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1    11162\n","2     2999\n","3     1522\n","Name: score_to_predict, dtype: int64"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["# Get the lists of lyrics and their labels.\n","texts = df.predict_from.values\n","labels = df.score_to_predict.values - 1"],"metadata":{"id":"UoV-IpY6FRZD","executionInfo":{"status":"ok","timestamp":1686190600705,"user_tz":240,"elapsed":389,"user":{"displayName":"Chandramani","userId":"15720194962338037264"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["np.unique(labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rLxP96YeFc-Y","executionInfo":{"status":"ok","timestamp":1686190602030,"user_tz":240,"elapsed":3,"user":{"displayName":"Chandramani","userId":"15720194962338037264"}},"outputId":"9b7633a9-40aa-4ef6-9dba-d597279a78a0"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 1])"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["df_train, df_valid = train_test_split(df, test_size = 0.2, stratify = df['score_to_predict'], random_state=42 )"],"metadata":{"id":"BIhQV6Xh1Q_r","executionInfo":{"status":"ok","timestamp":1686195559538,"user_tz":240,"elapsed":377,"user":{"displayName":"Chandramani","userId":"15720194962338037264"}}},"execution_count":115,"outputs":[]},{"cell_type":"code","source":["!pip install nlpaug"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3iK5HW8P0TPQ","executionInfo":{"status":"ok","timestamp":1686249670428,"user_tz":240,"elapsed":14137,"user":{"displayName":"Chandramani","userId":"15720194962338037264"}},"outputId":"54a21580-4ff7-4621-c59d-b05ea464644e"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting nlpaug\n","  Downloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (1.22.4)\n","Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (1.5.3)\n","Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (2.27.1)\n","Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (4.6.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (3.12.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (1.16.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.65.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.11.2)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2022.7.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.4)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (2.4.1)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (1.7.1)\n","Installing collected packages: nlpaug\n","Successfully installed nlpaug-1.1.11\n"]}]},{"cell_type":"code","source":["import nlpaug.augmenter.word as naw\n","\n","def detect_minority_majority_classes(df, label_column):\n","\n","    class_counts = df[label_column].value_counts()\n","    minority_classes = class_counts[class_counts < class_counts.max()].index.tolist()\n","    majority_class = class_counts.idxmax()\n","    return minority_classes, majority_class\n","\n","def augment_minority_class_text(df, text_column, label_column):\n"," \n","    augmented_texts = []\n","    aug = naw.SynonymAug()\n","    minority_classes, majority_class = detect_minority_majority_classes(df, label_column)\n","   \n","    for minority_class in minority_classes:\n","        # Filter the dataframe to get only the minority class rows\n","        minority_df = df[df[label_column] == minority_class]\n","        majority_df = df[df[label_column] == majority_class]\n","        minority_count = len(minority_df)\n","        majority_count = len(majority_df)\n","        \n","\n","        # Check if augmentation is required based on class imbalance\n","        if minority_count >= 0.8 * majority_count:\n","            continue\n","\n","        # Calculate the number of augmentations required\n","        num_augmentations = int(0.8 * majority_count) - minority_count\n","        print(num_augmentations)\n","        # Augment the text of the minority class\n","        while num_augmentations > 0:\n","            for text in minority_df[text_column]:\n","                augmented_text = aug.augment(text)\n","                augmented_texts.append(augmented_text)\n","                num_augmentations -= 1\n","                if num_augmentations == 0:\n","                    break\n","\n","        # Create a new dataframe with augmented texts\n","        augmented_df = pd.DataFrame({text_column: augmented_texts})\n","        print(augmented_df)\n","        augmented_df[label_column] = minority_class\n","        print(\"Value Counts = \" + str(augmented_df[label_column].value_counts()))    \n","        # Concatenate the augmented dataframe with the original dataframe\n","        augmented_df = pd.concat([df, augmented_df], ignore_index=True)\n","\n","    return augmented_df\n","\n"],"metadata":{"id":"z8cTDGYD1ObS","executionInfo":{"status":"ok","timestamp":1686249674403,"user_tz":240,"elapsed":4044,"user":{"displayName":"Chandramani","userId":"15720194962338037264"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["df_balanced = augment_minority_class_text(df_train, 'predict_from','assigned_score')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ae-jpH--1gU4","executionInfo":{"status":"ok","timestamp":1686196786972,"user_tz":240,"elapsed":1308,"user":{"displayName":"Chandramani","userId":"15720194962338037264"}},"outputId":"45a96898-bfc9-4c43-cb52-2022dc06bb60"},"execution_count":126,"outputs":[{"output_type":"stream","name":"stdout","text":["1926\n","Value Counts = 1    1926\n","Name: assigned_score, dtype: int64\n"]}]},{"cell_type":"code","source":["df_balanced['assigned_score'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yoPb_j-U4eOm","executionInfo":{"status":"ok","timestamp":1686196786973,"user_tz":240,"elapsed":9,"user":{"displayName":"Chandramani","userId":"15720194962338037264"}},"outputId":"b1a57f24-67be-4544-b5a3-cbab827b797a"},"execution_count":127,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2    5088\n","3    5032\n","1    4070\n","Name: assigned_score, dtype: int64"]},"metadata":{},"execution_count":127}]},{"cell_type":"code","source":["from transformers import ElectraTokenizer, ElectraForSequenceClassification,AdamW\n","import torch\n","tokenizer = ElectraTokenizer.from_pretrained('google/electra-large-discriminator')\n","model = ElectraForSequenceClassification.from_pretrained('google/electra-large-discriminator',num_labels=df['assigned_score'].nunique())\n","model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4SzCep0hFj9n","executionInfo":{"status":"ok","timestamp":1686196793845,"user_tz":240,"elapsed":4457,"user":{"displayName":"Chandramani","userId":"15720194962338037264"}},"outputId":"91cae75f-2532-47d0-ece4-c02e76f1631e"},"execution_count":128,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at google/electra-large-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias']\n","- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-large-discriminator and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["ElectraForSequenceClassification(\n","  (electra): ElectraModel(\n","    (embeddings): ElectraEmbeddings(\n","      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n","      (position_embeddings): Embedding(512, 1024)\n","      (token_type_embeddings): Embedding(2, 1024)\n","      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): ElectraEncoder(\n","      (layer): ModuleList(\n","        (0-23): 24 x ElectraLayer(\n","          (attention): ElectraAttention(\n","            (self): ElectraSelfAttention(\n","              (query): Linear(in_features=1024, out_features=1024, bias=True)\n","              (key): Linear(in_features=1024, out_features=1024, bias=True)\n","              (value): Linear(in_features=1024, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): ElectraSelfOutput(\n","              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): ElectraIntermediate(\n","            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): ElectraOutput(\n","            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (classifier): ElectraClassificationHead(\n","    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (out_proj): Linear(in_features=1024, out_features=3, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":128}]},{"cell_type":"code","source":["def extract_first_string(value):\n","    if isinstance(value, list):\n","        if len(value) > 0 and isinstance(value[0], str):\n","            return value[0]\n","    return value\n","\n","df_balanced['predict_from'] = df_balanced['predict_from'].apply(extract_first_string)    "],"metadata":{"id":"DZsYFUMh5U1a","executionInfo":{"status":"ok","timestamp":1686194853069,"user_tz":240,"elapsed":1587,"user":{"displayName":"Chandramani","userId":"15720194962338037264"}}},"execution_count":104,"outputs":[]},{"cell_type":"code","source":["train_texts = df_train.predict_from.values\n","train_labels = df_train.assigned_score.values - 1"],"metadata":{"id":"W9cLhgik5EOv","executionInfo":{"status":"ok","timestamp":1686195579825,"user_tz":240,"elapsed":526,"user":{"displayName":"Chandramani","userId":"15720194962338037264"}}},"execution_count":117,"outputs":[]},{"cell_type":"code","source":["train_indices = tokenizer.batch_encode_plus(\n","    train_texts,\n","    max_length=64,\n","    add_special_tokens=True,\n","    return_attention_mask=True,\n","    pad_to_max_length=True,\n","    truncation=True\n",")\n","\n","train_inputs = train_indices[\"input_ids\"]\n","train_masks = train_indices[\"attention_mask\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2svAGnVYFuc0","executionInfo":{"status":"ok","timestamp":1686195587315,"user_tz":240,"elapsed":3525,"user":{"displayName":"Chandramani","userId":"15720194962338037264"}},"outputId":"6e85b71e-ecbe-4820-b47e-de6124d3e6ab"},"execution_count":118,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["val_text = df_valid.predict_from.values\n","validation_labels= df_valid.assigned_score.values - 1\n","val_indices = tokenizer.batch_encode_plus(\n","    val_text,\n","    max_length=100,\n","    add_special_tokens=True,\n","    return_attention_mask=True,\n","    pad_to_max_length=True,\n","    truncation=True\n",")\n","\n","validation_inputs = val_indices[\"input_ids\"]\n","validation_masks = val_indices[\"attention_mask\"]"],"metadata":{"id":"zgpYBLuV7BRO","executionInfo":{"status":"ok","timestamp":1686195590231,"user_tz":240,"elapsed":1114,"user":{"displayName":"Chandramani","userId":"15720194962338037264"}}},"execution_count":119,"outputs":[]},{"cell_type":"code","source":["test_indexes = df_valid['student_id']"],"metadata":{"id":"XU--LACN7aBL","executionInfo":{"status":"ok","timestamp":1686195592121,"user_tz":240,"elapsed":2,"user":{"displayName":"Chandramani","userId":"15720194962338037264"}}},"execution_count":120,"outputs":[]},{"cell_type":"code","source":["# Convert all of our data into torch tensors, the required datatype for our model\n","train_inputs = torch.tensor(train_inputs)\n","validation_inputs = torch.tensor(validation_inputs)\n","train_labels = torch.tensor(train_labels, dtype=torch.long)\n","validation_labels = torch.tensor(validation_labels, dtype=torch.long)\n","train_masks = torch.tensor(train_masks, dtype=torch.long)\n","validation_masks = torch.tensor(validation_masks, dtype=torch.long)\n","train_inputs.shape, validation_inputs.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tqo8jQivGB9n","executionInfo":{"status":"ok","timestamp":1686195593678,"user_tz":240,"elapsed":1033,"user":{"displayName":"Chandramani","userId":"15720194962338037264"}},"outputId":"f5296811-e793-4313-e090-5c182518965a"},"execution_count":121,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([12264, 64]), torch.Size([3067, 100]))"]},"metadata":{},"execution_count":121}]},{"cell_type":"code","source":["from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","batch_size = 32\n","\n","# Create the DataLoader for our training set.\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","# Create the DataLoader for our validation set.\n","validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n","validation_sampler = SequentialSampler(validation_data)\n","validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"],"metadata":{"id":"c53bDmsuGETQ","executionInfo":{"status":"ok","timestamp":1686195596856,"user_tz":240,"elapsed":715,"user":{"displayName":"Chandramani","userId":"15720194962338037264"}}},"execution_count":122,"outputs":[]},{"cell_type":"code","source":["optimizer = AdamW(model.parameters(),\n","                  lr = 6e-6, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n","                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n","                )\n","\n","from transformers import get_linear_schedule_with_warmup\n","\n","# Number of training epochs (authors recommend between 2 and 4)\n","epochs = 10\n","\n","# Total number of training steps is number of batches * number of epochs.\n","total_steps = len(train_dataloader) * epochs\n","\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0, \n","                                            num_training_steps = total_steps)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"neHxF9MFGGWi","executionInfo":{"status":"ok","timestamp":1686195601698,"user_tz":240,"elapsed":522,"user":{"displayName":"Chandramani","userId":"15720194962338037264"}},"outputId":"47318140-8014-4dd0-8863-7c3c37e54b0e"},"execution_count":123,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["import numpy as np\n","\n","# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n"],"metadata":{"id":"LG2d_502GI_q","executionInfo":{"status":"ok","timestamp":1686194886746,"user_tz":240,"elapsed":7,"user":{"displayName":"Chandramani","userId":"15720194962338037264"}}},"execution_count":112,"outputs":[]},{"cell_type":"code","source":["import time\n","import datetime\n","\n","def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"metadata":{"id":"UWqLcjJbGL8m","executionInfo":{"status":"ok","timestamp":1686194889363,"user_tz":240,"elapsed":9,"user":{"displayName":"Chandramani","userId":"15720194962338037264"}}},"execution_count":113,"outputs":[]},{"cell_type":"code","source":["import random\n","from sklearn.utils.class_weight import compute_class_weight\n","\n","seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","loss_values = []\n","\n","# Compute class weights\n","class_counts = np.bincount(train_labels)\n","total_samples = len(train_labels)\n","class_weights = torch.tensor([total_samples / (len(class_counts) * count) for count in class_counts]).to(device)\n","print(class_weights)\n","\n","# For each epoch...\n","for epoch_i in range(0, epochs):\n","    \n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # Measure how long the training epoch takes.\n","    t0 = time.time()\n","\n","    total_loss = 0\n","\n","    model.train()\n","\n","    for step, batch in enumerate(train_dataloader):\n","\n","        # Progress update every 100 batches.\n","        if step % 50 == 0 and not step == 0:\n","            # Calculate elapsed time in minutes.\n","            elapsed = format_time(time.time() - t0)\n","            \n","            # Report progress.\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        model.zero_grad()        \n","\n","        outputs = model(b_input_ids, \n","                        token_type_ids=None, \n","                        attention_mask=b_input_mask, \n","                        labels=b_labels)\n","\n","        loss = outputs[0]\n","\n","        # Apply class weights to the loss\n","        loss = torch.mean(loss)\n","\n","        total_loss += loss.item()\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","        optimizer.step()\n","\n","        # Update the learning rate.\n","        scheduler.step()\n","\n","    # Calculate the average loss over the training data.\n","    avg_train_loss = total_loss / len(train_dataloader)            \n","    \n","    # Store the loss value for plotting the learning curve.\n","    loss_values.append(avg_train_loss)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epoch took: {:}\".format(format_time(time.time() - t0)))\n","\n","print(\"\")\n","print(\"Training complete!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_bCTF9RJGR3p","executionInfo":{"status":"ok","timestamp":1686196673477,"user_tz":240,"elapsed":1065528,"user":{"displayName":"Chandramani","userId":"15720194962338037264"}},"outputId":"8a122e3e-b7c2-432b-ffc7-910d16e8d4e3"},"execution_count":124,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1.9067, 0.8035, 0.8124], device='cuda:0', dtype=torch.float64)\n","\n","======== Epoch 1 / 10 ========\n","Training...\n","  Batch    50  of    384.    Elapsed: 0:00:14.\n","  Batch   100  of    384.    Elapsed: 0:00:28.\n","  Batch   150  of    384.    Elapsed: 0:00:42.\n","  Batch   200  of    384.    Elapsed: 0:00:56.\n","  Batch   250  of    384.    Elapsed: 0:01:10.\n","  Batch   300  of    384.    Elapsed: 0:01:24.\n","  Batch   350  of    384.    Elapsed: 0:01:38.\n","\n","  Average training loss: 1.04\n","  Training epoch took: 0:01:47\n","\n","======== Epoch 2 / 10 ========\n","Training...\n","  Batch    50  of    384.    Elapsed: 0:00:14.\n","  Batch   100  of    384.    Elapsed: 0:00:28.\n","  Batch   150  of    384.    Elapsed: 0:00:42.\n","  Batch   200  of    384.    Elapsed: 0:00:56.\n","  Batch   250  of    384.    Elapsed: 0:01:09.\n","  Batch   300  of    384.    Elapsed: 0:01:23.\n","  Batch   350  of    384.    Elapsed: 0:01:37.\n","\n","  Average training loss: 1.03\n","  Training epoch took: 0:01:46\n","\n","======== Epoch 3 / 10 ========\n","Training...\n","  Batch    50  of    384.    Elapsed: 0:00:14.\n","  Batch   100  of    384.    Elapsed: 0:00:28.\n","  Batch   150  of    384.    Elapsed: 0:00:42.\n","  Batch   200  of    384.    Elapsed: 0:00:56.\n","  Batch   250  of    384.    Elapsed: 0:01:09.\n","  Batch   300  of    384.    Elapsed: 0:01:23.\n","  Batch   350  of    384.    Elapsed: 0:01:37.\n","\n","  Average training loss: 1.01\n","  Training epoch took: 0:01:46\n","\n","======== Epoch 4 / 10 ========\n","Training...\n","  Batch    50  of    384.    Elapsed: 0:00:14.\n","  Batch   100  of    384.    Elapsed: 0:00:28.\n","  Batch   150  of    384.    Elapsed: 0:00:42.\n","  Batch   200  of    384.    Elapsed: 0:00:55.\n","  Batch   250  of    384.    Elapsed: 0:01:09.\n","  Batch   300  of    384.    Elapsed: 0:01:23.\n","  Batch   350  of    384.    Elapsed: 0:01:37.\n","\n","  Average training loss: 0.67\n","  Training epoch took: 0:01:46\n","\n","======== Epoch 5 / 10 ========\n","Training...\n","  Batch    50  of    384.    Elapsed: 0:00:14.\n","  Batch   100  of    384.    Elapsed: 0:00:28.\n","  Batch   150  of    384.    Elapsed: 0:00:42.\n","  Batch   200  of    384.    Elapsed: 0:00:55.\n","  Batch   250  of    384.    Elapsed: 0:01:09.\n","  Batch   300  of    384.    Elapsed: 0:01:23.\n","  Batch   350  of    384.    Elapsed: 0:01:37.\n","\n","  Average training loss: 0.56\n","  Training epoch took: 0:01:46\n","\n","======== Epoch 6 / 10 ========\n","Training...\n","  Batch    50  of    384.    Elapsed: 0:00:14.\n","  Batch   100  of    384.    Elapsed: 0:00:28.\n","  Batch   150  of    384.    Elapsed: 0:00:42.\n","  Batch   200  of    384.    Elapsed: 0:00:55.\n","  Batch   250  of    384.    Elapsed: 0:01:09.\n","  Batch   300  of    384.    Elapsed: 0:01:23.\n","  Batch   350  of    384.    Elapsed: 0:01:37.\n","\n","  Average training loss: 0.53\n","  Training epoch took: 0:01:46\n","\n","======== Epoch 7 / 10 ========\n","Training...\n","  Batch    50  of    384.    Elapsed: 0:00:14.\n","  Batch   100  of    384.    Elapsed: 0:00:28.\n","  Batch   150  of    384.    Elapsed: 0:00:42.\n","  Batch   200  of    384.    Elapsed: 0:00:55.\n","  Batch   250  of    384.    Elapsed: 0:01:09.\n","  Batch   300  of    384.    Elapsed: 0:01:23.\n","  Batch   350  of    384.    Elapsed: 0:01:37.\n","\n","  Average training loss: 0.51\n","  Training epoch took: 0:01:46\n","\n","======== Epoch 8 / 10 ========\n","Training...\n","  Batch    50  of    384.    Elapsed: 0:00:14.\n","  Batch   100  of    384.    Elapsed: 0:00:28.\n","  Batch   150  of    384.    Elapsed: 0:00:42.\n","  Batch   200  of    384.    Elapsed: 0:00:55.\n","  Batch   250  of    384.    Elapsed: 0:01:09.\n","  Batch   300  of    384.    Elapsed: 0:01:23.\n","  Batch   350  of    384.    Elapsed: 0:01:37.\n","\n","  Average training loss: 0.48\n","  Training epoch took: 0:01:47\n","\n","======== Epoch 9 / 10 ========\n","Training...\n","  Batch    50  of    384.    Elapsed: 0:00:14.\n","  Batch   100  of    384.    Elapsed: 0:00:28.\n","  Batch   150  of    384.    Elapsed: 0:00:42.\n","  Batch   200  of    384.    Elapsed: 0:00:56.\n","  Batch   250  of    384.    Elapsed: 0:01:09.\n","  Batch   300  of    384.    Elapsed: 0:01:23.\n","  Batch   350  of    384.    Elapsed: 0:01:37.\n","\n","  Average training loss: 0.46\n","  Training epoch took: 0:01:46\n","\n","======== Epoch 10 / 10 ========\n","Training...\n","  Batch    50  of    384.    Elapsed: 0:00:14.\n","  Batch   100  of    384.    Elapsed: 0:00:28.\n","  Batch   150  of    384.    Elapsed: 0:00:42.\n","  Batch   200  of    384.    Elapsed: 0:00:56.\n","  Batch   250  of    384.    Elapsed: 0:01:09.\n","  Batch   300  of    384.    Elapsed: 0:01:23.\n","  Batch   350  of    384.    Elapsed: 0:01:37.\n","\n","  Average training loss: 0.45\n","  Training epoch took: 0:01:47\n","\n","Training complete!\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import cohen_kappa_score\n","\n","print(\"\")\n","print(\"Running Validation...\")\n","\n","t0 = time.time()\n","\n","# Put the model in evaluation mode--the dropout layers behave differently\n","# during evaluation.\n","model.eval()\n","\n","preds = []\n","true = []\n","\n","# Tracking variables\n","eval_loss, eval_kappa = 0, 0\n","nb_eval_steps, nb_eval_examples = 0, 0\n","\n","# Evaluate data for one epoch\n","for batch in validation_dataloader:\n","\n","    # Add batch to GPU\n","    batch = tuple(t.to(device) for t in batch)\n","\n","    # Unpack the inputs from our dataloader\n","    b_input_ids, b_input_mask, b_labels = batch\n","\n","    # Telling the model not to compute or store gradients, saving memory and\n","    # speeding up validation\n","    with torch.no_grad():\n","\n","        # Forward pass, calculate logit predictions.\n","        # This will return the logits rather than the loss because we have\n","        # not provided labels.\n","        # token_type_ids is the same as the \"segment ids\", which \n","        # differentiates sentence 1 and 2 in 2-sentence tasks.\n","\n","        outputs = model(b_input_ids, \n","                        token_type_ids=None, \n","                        attention_mask=b_input_mask)\n","\n","    # Get the \"logits\" output by the model. The \"logits\" are the output\n","    # values prior to applying an activation function like the softmax.\n","    logits = outputs[0]\n","\n","    # Move logits and labels to CPU\n","    logits = logits.detach().cpu().numpy()\n","    label_ids = b_labels.to('cpu').numpy()\n","\n","    preds.append(logits)\n","    true.append(label_ids)\n","\n","    # Calculate the Cohen's kappa coefficient for this batch of test sentences.\n","    tmp_eval_kappa = cohen_kappa_score(np.argmax(logits, axis=1), label_ids)\n","\n","    # Accumulate the total kappa coefficient.\n","    eval_kappa += tmp_eval_kappa\n","\n","    # Track the number of batches\n","    nb_eval_steps += 1\n","\n","df_results = pd.DataFrame({'indexes' : test_indexes,\n","        'true_labels': np.concatenate(true) + 1,\n","                           'predicted_labels': np.concatenate(preds).argmax(axis=1) + 1})    \n","# Report the final kappa coefficient for this validation run.\n","print(\"  Cohen's Kappa: {0:.2f}\".format(eval_kappa / nb_eval_steps))\n","print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AzTKcV0fGaef","executionInfo":{"status":"ok","timestamp":1686196690781,"user_tz":240,"elapsed":13138,"user":{"displayName":"Chandramani","userId":"15720194962338037264"}},"outputId":"d85f3c32-631c-4d0d-fe7c-f0dff9b9f9ae"},"execution_count":125,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Running Validation...\n","  Cohen's Kappa: 0.67\n","  Validation took: 0:00:12\n"]}]},{"cell_type":"code","source":["df_results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"O2eRISvZZHiI","executionInfo":{"status":"ok","timestamp":1686183903414,"user_tz":240,"elapsed":559,"user":{"displayName":"Chandramani","userId":"15720194962338037264"}},"outputId":"e1c490a9-bc8c-45c0-819a-04d7fb14a013"},"execution_count":201,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      indexes  true_labels  predicted_labels\n","0       11336            1                 1\n","1        9634            1                 1\n","2        1979            1                 1\n","3        3602            2                 2\n","4        6348            1                 1\n","...       ...          ...               ...\n","2688     7971            1                 1\n","2689     8235            1                 1\n","2690    10800            2                 2\n","2691     7462            1                 1\n","2692     2155            1                 1\n","\n","[2693 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-8a68a9f8-884c-49f2-9d3a-13aabf55ef36\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>indexes</th>\n","      <th>true_labels</th>\n","      <th>predicted_labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>11336</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>9634</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1979</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3602</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6348</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2688</th>\n","      <td>7971</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2689</th>\n","      <td>8235</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2690</th>\n","      <td>10800</td>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2691</th>\n","      <td>7462</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2692</th>\n","      <td>2155</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2693 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8a68a9f8-884c-49f2-9d3a-13aabf55ef36')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-8a68a9f8-884c-49f2-9d3a-13aabf55ef36 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8a68a9f8-884c-49f2-9d3a-13aabf55ef36');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":201}]},{"cell_type":"code","source":["# Filter rows where true_labels are not equal to predicted_labels\n","mismatched_rows = df_results[df_results['true_labels'] == 3]\n","\n","# Print the mismatched rows\n","print(mismatched_rows)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XGlDjv9gZgWq","executionInfo":{"status":"ok","timestamp":1686184045769,"user_tz":240,"elapsed":355,"user":{"displayName":"Chandramani","userId":"15720194962338037264"}},"outputId":"65aa20f8-3794-4c97-d5dc-87718acda506"},"execution_count":204,"outputs":[{"output_type":"stream","name":"stdout","text":["      indexes  true_labels  predicted_labels\n","1079     2120            3                 1\n","1376     3838            3                 2\n"]}]},{"cell_type":"code","source":["def dataprocess(df) : \n","  df = df.dropna(subset = ['predict_from'])\n","  df['predict_from'] = df['predict_from'].apply(preprocess)\n","  # Get the lists of lyrics and their labels.\n","  df_train, df_valid = train_test_split(df, test_size = 0.2, stratify = df['score_to_predict'], random_state=42)\n","  df_balanced = augment_minority_class_text(df_train, 'predict_from','assigned_score')\n","  df_balanced['predict_from'] = df_balanced['predict_from'].apply(extract_first_string) \n","  train_texts = df_balanced.predict_from.values\n","  train_labels = df_balanced.assigned_score.values - 1 \n","  train_indices = tokenizer.batch_encode_plus(train_texts,max_length=64,add_special_tokens=True,return_attention_mask=True,\n","    pad_to_max_length=True, truncation=True)\n","  test_indexes = df_valid.student_id.values\n","\n","  train_inputs = train_indices[\"input_ids\"]\n","  train_masks = train_indices[\"attention_mask\"]\n","  val_text = df_valid.predict_from.values\n","  validation_labels= df_valid.assigned_score.values - 1\n","  val_indices = tokenizer.batch_encode_plus(val_text,max_length=64,add_special_tokens=True, return_attention_mask=True,\n","      pad_to_max_length=True, truncation=True)\n","\n","  validation_inputs = val_indices[\"input_ids\"]\n","  validation_masks = val_indices[\"attention_mask\"]\n","  \n","  train_inputs = torch.tensor(train_inputs)\n","  validation_inputs = torch.tensor(validation_inputs)\n","  train_labels = torch.tensor(train_labels, dtype=torch.long)\n","  validation_labels = torch.tensor(validation_labels, dtype=torch.long)\n","  train_masks = torch.tensor(train_masks, dtype=torch.long)\n","  validation_masks = torch.tensor(validation_masks, dtype=torch.long)\n","\n","  batch_size = 32\n","\n","  # Create the DataLoader for our training set.\n","  train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","  train_sampler = RandomSampler(train_data)\n","  train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","  # Create the DataLoader for our validation set.\n","  validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n","  validation_sampler = SequentialSampler(validation_data)\n","  validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n","\n","  return train_dataloader,validation_dataloader, test_indexes\n","\n"],"metadata":{"id":"03bNGodnJkXm","executionInfo":{"status":"ok","timestamp":1686197466832,"user_tz":240,"elapsed":4,"user":{"displayName":"Chandramani","userId":"15720194962338037264"}}},"execution_count":138,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kJLYvK3xNNTQ","executionInfo":{"status":"ok","timestamp":1686181093091,"user_tz":240,"elapsed":3542,"user":{"displayName":"Chandramani","userId":"15720194962338037264"}},"outputId":"b1fdd4ed-dfcd-4d1c-a633-f16b7b0bcef3"},"execution_count":128,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["def train(model, train_dataloader, validation_dataloader, test_indexes) :\n","    seed_val = 42\n","    epoches = 10\n","    random.seed(seed_val)\n","    np.random.seed(seed_val)\n","    torch.manual_seed(seed_val)\n","    torch.cuda.manual_seed_all(seed_val)\n","\n","    loss_values = []\n","\n","    # Compute class weights\n","    class_counts = np.bincount(train_labels)\n","    total_samples = len(train_labels)\n","    class_weights = torch.tensor([total_samples / (len(class_counts) * count) for count in class_counts]).to(device)\n","    print(class_weights)\n","\n","    # For each epoch...\n","    for epoch_i in range(0, epoches):\n","        \n","        print(\"\")\n","        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","        print('Training...')\n","\n","        # Measure how long the training epoch takes.\n","        t0 = time.time()\n","\n","        total_loss = 0\n","\n","        model.train()\n","\n","        for step, batch in enumerate(train_dataloader):\n","\n","            # Progress update every 100 batches.\n","            if step % 100 == 0 and not step == 0:\n","                # Calculate elapsed time in minutes.\n","                elapsed = format_time(time.time() - t0)\n","                \n","                # Report progress.\n","                print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","            b_input_ids = batch[0].to(device)\n","            b_input_mask = batch[1].to(device)\n","            b_labels = batch[2].to(device)\n","\n","            model.zero_grad()        \n","\n","            outputs = model(b_input_ids, \n","                            token_type_ids=None, \n","                            attention_mask=b_input_mask, \n","                            labels=b_labels)\n","\n","            loss = outputs[0]\n","\n","            # Apply class weights to the loss\n","            loss = torch.mean(loss )\n","\n","            total_loss += loss.item()\n","            loss.backward()\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","            optimizer.step()\n","\n","            # Update the learning rate.\n","            scheduler.step()\n","\n","        # Calculate the average loss over the training data.\n","        avg_train_loss = total_loss / len(train_dataloader)            \n","        \n","        # Store the loss value for plotting the learning curve.\n","        loss_values.append(avg_train_loss)\n","\n","        print(\"\")\n","        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","        print(\"  Training epoch took: {:}\".format(format_time(time.time() - t0)))\n","\n","    print(\"\")\n","    print(\"Training complete!\")\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","\n","    # Put the model in evaluation mode--the dropout layers behave differently\n","    # during evaluation.\n","    model.eval()\n","\n","    preds = []\n","    true = []\n","\n","    # Tracking variables\n","    eval_loss, eval_kappa = 0, 0\n","    nb_eval_steps, nb_eval_examples = 0, 0\n","\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","\n","        # Add batch to GPU\n","        batch = tuple(t.to(device) for t in batch)\n","\n","        # Unpack the inputs from our dataloader\n","        b_input_ids, b_input_mask, b_labels = batch\n","\n","        # Telling the model not to compute or store gradients, saving memory and\n","        # speeding up validation\n","        with torch.no_grad():\n","\n","            # Forward pass, calculate logit predictions.\n","            # This will return the logits rather than the loss because we have\n","            # not provided labels.\n","            # token_type_ids is the same as the \"segment ids\", which \n","            # differentiates sentence 1 and 2 in 2-sentence tasks.\n","\n","            outputs = model(b_input_ids, \n","                            token_type_ids=None, \n","                            attention_mask=b_input_mask)\n","\n","        # Get the \"logits\" output by the model. The \"logits\" are the output\n","        # values prior to applying an activation function like the softmax.\n","        logits = outputs[0]\n","\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        preds.append(logits)\n","        true.append(label_ids)\n","\n","        # Calculate the Cohen's kappa coefficient for this batch of test sentences.\n","        tmp_eval_kappa = cohen_kappa_score(np.argmax(logits, axis=1), label_ids, weights='quadratic')\n","\n","        # Accumulate the total kappa coefficient.\n","        eval_kappa += tmp_eval_kappa\n","\n","\n","        # Track the number of batches\n","        nb_eval_steps += 1\n","\n","    df_results = pd.DataFrame({'indexes' : test_indexes,\n","        'true_labels': np.concatenate(true),\n","                           'predicted_labels': np.concatenate(preds).argmax(axis=1)})\n","    # Report the final kappa coefficient for this validation run.\n","    print(\"  Cohen's Kappa: {0:.2f}\".format(eval_kappa / nb_eval_steps))\n","    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n","\n"],"metadata":{"id":"l7nolCAnO45J","executionInfo":{"status":"ok","timestamp":1686197379234,"user_tz":240,"elapsed":1069,"user":{"displayName":"Chandramani","userId":"15720194962338037264"}}},"execution_count":135,"outputs":[]},{"cell_type":"code","source":["def train_model(df, name) :\n","  tokenizer = ElectraTokenizer.from_pretrained('google/electra-large-discriminator')\n","  model = ElectraForSequenceClassification.from_pretrained('google/electra-large-discriminator',num_labels=df['score_to_predict'].nunique())\n","  model.to(device)\n","  train_dataloader, validation_dataloader, test_indexes = dataprocess(df)\n","  train(model,train_dataloader,validation_dataloader, test_indexes)\n","\n"],"metadata":{"id":"F03tcv7GNQpw","executionInfo":{"status":"ok","timestamp":1686197387166,"user_tz":240,"elapsed":963,"user":{"displayName":"Chandramani","userId":"15720194962338037264"}}},"execution_count":136,"outputs":[]},{"cell_type":"code","source":["train_model(df,'test')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"PN_yu41ZOmL8","executionInfo":{"status":"error","timestamp":1686197983119,"user_tz":240,"elapsed":511125,"user":{"displayName":"Chandramani","userId":"15720194962338037264"}},"outputId":"67b2b7a7-9ed7-4e0f-aa8a-72c8cc818877"},"execution_count":139,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at google/electra-large-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias']\n","- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-large-discriminator and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["1926\n","Value Counts = 1    1926\n","Name: assigned_score, dtype: int64\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2354: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["tensor([1.9067, 0.8035, 0.8124], device='cuda:0', dtype=torch.float64)\n","\n","======== Epoch 1 / 10 ========\n","Training...\n","  Batch   100  of    444.    Elapsed: 0:00:28.\n","  Batch   200  of    444.    Elapsed: 0:00:56.\n","  Batch   300  of    444.    Elapsed: 0:01:23.\n","  Batch   400  of    444.    Elapsed: 0:01:51.\n","\n","  Average training loss: 1.11\n","  Training epoch took: 0:02:03\n","\n","======== Epoch 2 / 10 ========\n","Training...\n","  Batch   100  of    444.    Elapsed: 0:00:28.\n","  Batch   200  of    444.    Elapsed: 0:00:56.\n","  Batch   300  of    444.    Elapsed: 0:01:24.\n","  Batch   400  of    444.    Elapsed: 0:01:51.\n","\n","  Average training loss: 1.11\n","  Training epoch took: 0:02:03\n","\n","======== Epoch 3 / 10 ========\n","Training...\n","  Batch   100  of    444.    Elapsed: 0:00:28.\n","  Batch   200  of    444.    Elapsed: 0:00:56.\n","  Batch   300  of    444.    Elapsed: 0:01:23.\n","  Batch   400  of    444.    Elapsed: 0:01:51.\n","\n","  Average training loss: 1.11\n","  Training epoch took: 0:02:03\n","\n","======== Epoch 4 / 10 ========\n","Training...\n","  Batch   100  of    444.    Elapsed: 0:00:28.\n","  Batch   200  of    444.    Elapsed: 0:00:56.\n","  Batch   300  of    444.    Elapsed: 0:01:24.\n","  Batch   400  of    444.    Elapsed: 0:01:51.\n","\n","  Average training loss: 1.11\n","  Training epoch took: 0:02:03\n","\n","======== Epoch 5 / 10 ========\n","Training...\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n","\u001b[31m│\u001b[0m in \u001b[92m<cell line: 1>\u001b[0m:\u001b[94m1\u001b[0m                                                                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m in \u001b[92mtrain_model\u001b[0m:\u001b[94m6\u001b[0m                                                                                 \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m in \u001b[92mtrain\u001b[0m:\u001b[94m59\u001b[0m                                                                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/nn/utils/\u001b[0m\u001b[1;33mclip_grad.py\u001b[0m:\u001b[94m61\u001b[0m in \u001b[92mclip_grad_norm_\u001b[0m        \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 58 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 59 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mnorms.extend([torch.norm(g, norm_type) \u001b[94mfor\u001b[0m g \u001b[95min\u001b[0m grads])                    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 60 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 61 \u001b[2m│   │   \u001b[0mtotal_norm = torch.norm(torch.stack([norm.to(first_device) \u001b[94mfor\u001b[0m norm \u001b[95min\u001b[0m norms]),    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 62 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 63 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m error_if_nonfinite \u001b[95mand\u001b[0m torch.logical_or(total_norm.isnan(), total_norm.isinf()):    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 64 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mRuntimeError\u001b[0m(                                                                \u001b[31m│\u001b[0m\n","\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n","\u001b[1;91mKeyboardInterrupt\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 1&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train_model</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">6</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">59</span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/nn/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">clip_grad.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">61</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">clip_grad_norm_</span>        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 58 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 59 │   │   │   │   </span>norms.extend([torch.norm(g, norm_type) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> g <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> grads])                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 60 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 61 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>total_norm = torch.norm(torch.stack([norm.to(first_device) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> norm <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> norms]),    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 62 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 63 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> error_if_nonfinite <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> torch.logical_or(total_norm.isnan(), total_norm.isinf()):    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 64 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">RuntimeError</span>(                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n","<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n","</pre>\n"]},"metadata":{}}]}]}